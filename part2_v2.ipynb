{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218bfea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install swig\n",
    "#! pip install gymnasium\n",
    "#! pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3f2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box([ -2.5        -2.5       -10.        -10.         -6.2831855 -10.\n",
      "  -0.         -0.       ], [ 2.5        2.5       10.        10.         6.2831855 10.\n",
      "  1.         1.       ], (8,), float32)\n",
      "Action space: Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LunarLander-v3\", gravity=-10, continuous=False,\n",
    "               enable_wind=False, wind_power=15.0, turbulence_power=1.5, render_mode=\"human\")\n",
    "\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf50175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_shape = env.observation_space.shape\n",
    "state_size = env.observation_space.shape[0]\n",
    "number_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6facd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "State size:  8\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "print('State shape: ', state_shape)\n",
    "print('State size: ', state_size)\n",
    "print('Number of actions: ', number_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21ccfdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 [-0.01009436  1.4324743  -0.5105347   0.4660997   0.01157735  0.11445676\n",
      "  0.          0.        ] 0.1858657333372662 False {}\n",
      "Step: 10 [-0.06027079  1.5266532  -0.50324285  0.33686206  0.11166158  0.21179609\n",
      "  0.          0.        ] -0.31516889786095703 False {}\n",
      "Step: 20 [-0.11133957  1.5774624  -0.5272395   0.15763761  0.2108048   0.20768246\n",
      "  0.          0.        ] -2.0702949754981317 False {}\n",
      "Step: 30 [-0.16043147  1.5910816  -0.49849743  0.0114089   0.23179713  0.00687036\n",
      "  0.          0.        ] 0.8760807845223166 False {}\n",
      "Step: 40 [-0.21322484  1.5685438  -0.5610288  -0.18028833  0.26729608  0.12295918\n",
      "  0.          0.        ] -0.18347738825332158 False {}\n",
      "Step: 50 [-0.26904878  1.5115747  -0.5800433  -0.34512576  0.32856005  0.15366141\n",
      "  0.          0.        ] -0.660436256033903 False {}\n",
      "Step: 60 [-0.33143336  1.4226122  -0.6731488  -0.47572282  0.42020383  0.22969678\n",
      "  0.          0.        ] -2.7894439530379302 False {}\n",
      "Step: 70 [-0.40377063  1.2979972  -0.78295743 -0.62187934  0.5782996   0.38567105\n",
      "  0.          0.        ] -1.6869869839476224 False {}\n",
      "Step: 80 [-0.48732582  1.1376989  -0.91362584 -0.7994632   0.7753447   0.4228324\n",
      "  0.          0.        ] -3.3281174429754103 False {}\n",
      "Step: 90 [-0.5965842   0.94818234 -1.2020559  -0.9426616   0.9815604   0.48355335\n",
      "  0.          0.        ] -3.6758995481539203 False {}\n",
      "Step: 100 [-0.7203741   0.71363485 -1.3259492  -1.1287302   1.1587074   0.31245023\n",
      "  0.          0.        ] -4.025229448205027 False {}\n",
      "Step: 110 [-0.8646996   0.4364603  -1.5531181  -1.3319873   1.346997    0.41319728\n",
      "  0.          0.        ] -7.525931911986947 False {}\n",
      "Step: 120 [-1.0251513   0.15949424 -1.6851469  -0.9320764   2.3161764   5.827606\n",
      "  0.          1.        ] -100 True {}\n",
      "Step: 130 [-1.2126789  -0.11009133 -1.7383235  -1.2364746   5.1550756   5.6143107\n",
      "  0.          0.        ] -100 True {}\n",
      "Step: 140 [-1.3664328  -0.41281658 -1.8051131  -1.4918252   7.9205647   5.4408193\n",
      "  0.          0.        ] -100 True {}\n",
      "Step: 150 [-1.5709286  -0.78144443 -1.7672625  -1.8306401  10.564939    5.1055503\n",
      "  0.          0.        ] -100 True {}\n",
      "Step: 160 [-1.7261322 -1.2298943 -1.5950071 -1.9454182 13.068927   4.8980837\n",
      "  0.         0.       ] -100 True {}\n",
      "Step: 170 [-1.901106  -1.6774523 -1.8265921 -2.2676928 15.550069   4.9567447\n",
      "  0.         0.       ] -100 True {}\n",
      "Step: 180 [-2.0922465 -2.2543128 -1.7983013 -2.5768063 17.963074   4.7720804\n",
      "  0.         0.       ] -100 True {}\n",
      "Step: 190 [-2.255032  -2.8576713 -1.8284525 -2.8144412 20.266594   4.512852\n",
      "  0.         0.       ] -100 True {}\n",
      "Step: 200 [-2.467065  -3.5081615 -1.9930884 -3.1230211 22.472183   4.299562\n",
      "  0.         0.       ] -100 True {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def random_policy(env, state):\n",
    "    return env.action_space.sample()\n",
    "\n",
    "state = env.reset()[0]\n",
    "\n",
    "for counter in range(201):\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    #select the action according to the given policy\n",
    "    action = random_policy(env, state)\n",
    "    \n",
    "    #perform the action and store the next state information\n",
    "    next_state, reward, done, truncated, info = env.step(action)\n",
    "\n",
    "    if counter % 10 == 0:\n",
    "        print(\"Step:\", counter, next_state, reward, done, info)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f351617",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", gravity=-10, continuous=True,\n",
    "               enable_wind=False, wind_power=15.0, turbulence_power=1.5)\n",
    "env.reset(seed=seed_value)\n",
    "\n",
    "\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_low = float(env.action_space.low[0])\n",
    "action_high = float(env.action_space.high[0])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21a78634",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3b7dd6",
   "metadata": {},
   "source": [
    "## stable-baselines DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c488a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 77.2     |\n",
      "|    ep_rew_mean     | -408     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 229      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 309      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.05     |\n",
      "|    critic_loss     | 38.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 208      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 101      |\n",
      "|    ep_rew_mean     | -335     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 184      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 811      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.99     |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 710      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 110      |\n",
      "|    ep_rew_mean     | -266     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 172      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 1314     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.18     |\n",
      "|    critic_loss     | 3.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1213     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 132      |\n",
      "|    ep_rew_mean     | -284     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 167      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 2110     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.34     |\n",
      "|    critic_loss     | 9.67     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2009     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | -256     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 162      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 4189     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 0.379    |\n",
      "|    critic_loss     | 6.89     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4088     |\n",
      "---------------------------------\n",
      "Evaluation at step 5000: Mean Reward = -51.75\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | -213     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 6001     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.4    |\n",
      "|    critic_loss     | 28       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5900     |\n",
      "---------------------------------\n",
      "Evaluation at step 10000: Mean Reward = -26.91\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 357      |\n",
      "|    ep_rew_mean     | -186     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 666      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 10001    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 438      |\n",
      "|    ep_rew_mean     | -172     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 14001    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -67.6    |\n",
      "|    critic_loss     | 3.8      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13900    |\n",
      "---------------------------------\n",
      "Evaluation at step 15000: Mean Reward = -52.43\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 496      |\n",
      "|    ep_rew_mean     | -173     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 17866    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -85.5    |\n",
      "|    critic_loss     | 4.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17765    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 480      |\n",
      "|    ep_rew_mean     | -162     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 156      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 19181    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.1    |\n",
      "|    critic_loss     | 24.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19080    |\n",
      "---------------------------------\n",
      "Evaluation at step 20000: Mean Reward = -67.63\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 504      |\n",
      "|    ep_rew_mean     | -155     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 22156    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22055    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 508      |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 24362    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 6.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24261    |\n",
      "---------------------------------\n",
      "Evaluation at step 25000: Mean Reward = -103.72\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 538      |\n",
      "|    ep_rew_mean     | -150     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 156      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 28001    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 7.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27900    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 523      |\n",
      "|    ep_rew_mean     | -153     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 156      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 29302    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 37.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29201    |\n",
      "---------------------------------\n",
      "Evaluation at step 30000: Mean Reward = -194.81\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 516      |\n",
      "|    ep_rew_mean     | -150     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 30950    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -119     |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30849    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 513      |\n",
      "|    ep_rew_mean     | -154     |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 155      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 32835    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -126     |\n",
      "|    critic_loss     | 25.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32734    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 502      |\n",
      "|    ep_rew_mean     | -149     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 156      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 34125    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 33.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34024    |\n",
      "---------------------------------\n",
      "Evaluation at step 35000: Mean Reward = -71.34\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 491      |\n",
      "|    ep_rew_mean     | -153     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 35334    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 7.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35233    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 477      |\n",
      "|    ep_rew_mean     | -151     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 36218    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 272      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36117    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 469      |\n",
      "|    ep_rew_mean     | -154     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 37524    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 4.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37423    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 462      |\n",
      "|    ep_rew_mean     | -158     |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 38778    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -135     |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38677    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 447      |\n",
      "|    ep_rew_mean     | -159     |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 39334    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39233    |\n",
      "---------------------------------\n",
      "Evaluation at step 40000: Mean Reward = -196.81\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 439      |\n",
      "|    ep_rew_mean     | -160     |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 40382    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -145     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40281    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 424      |\n",
      "|    ep_rew_mean     | -156     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 40721    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 4.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40620    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 420      |\n",
      "|    ep_rew_mean     | -158     |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 41982    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -143     |\n",
      "|    critic_loss     | 25.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41881    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 434      |\n",
      "|    ep_rew_mean     | -149     |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 43731    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 7.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43630    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 435      |\n",
      "|    ep_rew_mean     | -144     |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 44351    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 32.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44250    |\n",
      "---------------------------------\n",
      "Evaluation at step 45000: Mean Reward = -167.11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 446      |\n",
      "|    ep_rew_mean     | -145     |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 45880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 13.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 453      |\n",
      "|    ep_rew_mean     | -137     |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 47440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -150     |\n",
      "|    critic_loss     | 357      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 449      |\n",
      "|    ep_rew_mean     | -135     |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 49052    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -160     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48951    |\n",
      "---------------------------------\n",
      "Evaluation at step 50000: Mean Reward = -222.47\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 453      |\n",
      "|    ep_rew_mean     | -140     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 151      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 51348    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -158     |\n",
      "|    critic_loss     | 21       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51247    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 445      |\n",
      "|    ep_rew_mean     | -140     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 54491    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -179     |\n",
      "|    critic_loss     | 78.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 54390    |\n",
      "---------------------------------\n",
      "Evaluation at step 55000: Mean Reward = -80.28\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 414      |\n",
      "|    ep_rew_mean     | -141     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 55428    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 884      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 55327    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 398      |\n",
      "|    ep_rew_mean     | -134     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 57638    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 30.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 57537    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 399      |\n",
      "|    ep_rew_mean     | -134     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 59091    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -173     |\n",
      "|    critic_loss     | 146      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 58990    |\n",
      "---------------------------------\n",
      "Evaluation at step 60000: Mean Reward = -149.38\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 390      |\n",
      "|    ep_rew_mean     | -131     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 154      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 61162    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -185     |\n",
      "|    critic_loss     | 44.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 61061    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 371      |\n",
      "|    ep_rew_mean     | -126     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 61441    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 15.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 61340    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 339      |\n",
      "|    ep_rew_mean     | -127     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 61881    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -186     |\n",
      "|    critic_loss     | 24.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 61780    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | -121     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 64033    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 131      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 63932    |\n",
      "---------------------------------\n",
      "Evaluation at step 65000: Mean Reward = -12.64\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | -117     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 66001    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -191     |\n",
      "|    critic_loss     | 62.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 65900    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 363      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 153      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 69091    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -196     |\n",
      "|    critic_loss     | 13.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 68990    |\n",
      "---------------------------------\n",
      "Evaluation at step 70000: Mean Reward = -42.96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 381      |\n",
      "|    ep_rew_mean     | -110     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 72216    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -204     |\n",
      "|    critic_loss     | 29.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 72115    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 395      |\n",
      "|    ep_rew_mean     | -104     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 74857    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -200     |\n",
      "|    critic_loss     | 89.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 74756    |\n",
      "---------------------------------\n",
      "Evaluation at step 75000: Mean Reward = 2.19\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 413      |\n",
      "|    ep_rew_mean     | -97.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 149      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 77529    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -201     |\n",
      "|    critic_loss     | 17.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 77428    |\n",
      "---------------------------------\n",
      "Evaluation at step 80000: Mean Reward = 147.85\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 432      |\n",
      "|    ep_rew_mean     | -86      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 80713    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -193     |\n",
      "|    critic_loss     | 22.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 80612    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 448      |\n",
      "|    ep_rew_mean     | -75.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 83599    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -200     |\n",
      "|    critic_loss     | 78.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 83498    |\n",
      "---------------------------------\n",
      "Evaluation at step 85000: Mean Reward = 57.86\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 458      |\n",
      "|    ep_rew_mean     | -67.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 152      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 85135    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -198     |\n",
      "|    critic_loss     | 10       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 85034    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | -60.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 88586    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -190     |\n",
      "|    critic_loss     | 38.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 88485    |\n",
      "---------------------------------\n",
      "Evaluation at step 90000: Mean Reward = 74.51\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 493      |\n",
      "|    ep_rew_mean     | -60.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 1979     |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 90001    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 508      |\n",
      "|    ep_rew_mean     | -57.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 92819    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -194     |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 92718    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 509      |\n",
      "|    ep_rew_mean     | -50.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 94644    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 29.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 94543    |\n",
      "---------------------------------\n",
      "Evaluation at step 95000: Mean Reward = -49.96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 508      |\n",
      "|    ep_rew_mean     | -47.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 95180    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -201     |\n",
      "|    critic_loss     | 42.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 95079    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 510      |\n",
      "|    ep_rew_mean     | -41.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 96872    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -201     |\n",
      "|    critic_loss     | 17.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 96771    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 502      |\n",
      "|    ep_rew_mean     | -37.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 97657    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -192     |\n",
      "|    critic_loss     | 252      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 97556    |\n",
      "---------------------------------\n",
      "Evaluation at step 100000: Mean Reward = -46.42\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 509      |\n",
      "|    ep_rew_mean     | -36.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 983      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 100001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 518      |\n",
      "|    ep_rew_mean     | -32.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 103123   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -203     |\n",
      "|    critic_loss     | 24.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 103022   |\n",
      "---------------------------------\n",
      "Evaluation at step 105000: Mean Reward = -62.99\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 507      |\n",
      "|    ep_rew_mean     | -32.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 105196   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -203     |\n",
      "|    critic_loss     | 30.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 105095   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 513      |\n",
      "|    ep_rew_mean     | -31      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 106750   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -198     |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 106649   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 513      |\n",
      "|    ep_rew_mean     | -33.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 108948   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -198     |\n",
      "|    critic_loss     | 94.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 108847   |\n",
      "---------------------------------\n",
      "Evaluation at step 110000: Mean Reward = -27.92\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 527      |\n",
      "|    ep_rew_mean     | -33.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 111827   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -189     |\n",
      "|    critic_loss     | 9.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 111726   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 523      |\n",
      "|    ep_rew_mean     | -30.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 113460   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -180     |\n",
      "|    critic_loss     | 18.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 113359   |\n",
      "---------------------------------\n",
      "Evaluation at step 115000: Mean Reward = -67.54\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 549      |\n",
      "|    ep_rew_mean     | -27.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 116331   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -174     |\n",
      "|    critic_loss     | 227      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 116230   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 573      |\n",
      "|    ep_rew_mean     | -30      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 119135   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -181     |\n",
      "|    critic_loss     | 8.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 119034   |\n",
      "---------------------------------\n",
      "Evaluation at step 120000: Mean Reward = -97.91\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 577      |\n",
      "|    ep_rew_mean     | -30.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 121714   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -178     |\n",
      "|    critic_loss     | 47.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 121613   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 575      |\n",
      "|    ep_rew_mean     | -35.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 123505   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -169     |\n",
      "|    critic_loss     | 11       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 123404   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 558      |\n",
      "|    ep_rew_mean     | -31.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 124900   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -166     |\n",
      "|    critic_loss     | 9.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 124799   |\n",
      "---------------------------------\n",
      "Evaluation at step 125000: Mean Reward = -89.97\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 544      |\n",
      "|    ep_rew_mean     | -30.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 126579   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -172     |\n",
      "|    critic_loss     | 10.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 126478   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 535      |\n",
      "|    ep_rew_mean     | -31.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 128378   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -168     |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 128277   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 522      |\n",
      "|    ep_rew_mean     | -33.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 129761   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -170     |\n",
      "|    critic_loss     | 20       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 129660   |\n",
      "---------------------------------\n",
      "Evaluation at step 130000: Mean Reward = -160.54\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 503      |\n",
      "|    ep_rew_mean     | -36.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 130989   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -162     |\n",
      "|    critic_loss     | 355      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 130888   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 489      |\n",
      "|    ep_rew_mean     | -43.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 132537   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -163     |\n",
      "|    critic_loss     | 22.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 132436   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 490      |\n",
      "|    ep_rew_mean     | -49.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 134128   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -162     |\n",
      "|    critic_loss     | 10.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 134027   |\n",
      "---------------------------------\n",
      "Evaluation at step 135000: Mean Reward = -121.22\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 465      |\n",
      "|    ep_rew_mean     | -54.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 135091   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -157     |\n",
      "|    critic_loss     | 663      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 134990   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 477      |\n",
      "|    ep_rew_mean     | -53.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 137693   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -157     |\n",
      "|    critic_loss     | 7.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 137592   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | -50.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 138447   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 7.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 138346   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 444      |\n",
      "|    ep_rew_mean     | -53.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 304      |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 139038   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -146     |\n",
      "|    critic_loss     | 14.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 138937   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 445      |\n",
      "|    ep_rew_mean     | -52.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 308      |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 139688   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -158     |\n",
      "|    critic_loss     | 17.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 139587   |\n",
      "---------------------------------\n",
      "Evaluation at step 140000: Mean Reward = 64.10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 445      |\n",
      "|    ep_rew_mean     | -56      |\n",
      "| time/              |          |\n",
      "|    episodes        | 312      |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 141331   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -155     |\n",
      "|    critic_loss     | 7.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 141230   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 451      |\n",
      "|    ep_rew_mean     | -53.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 316      |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 142722   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -150     |\n",
      "|    critic_loss     | 30.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 142621   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 446      |\n",
      "|    ep_rew_mean     | -50.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 144644   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 43.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 144543   |\n",
      "---------------------------------\n",
      "Evaluation at step 145000: Mean Reward = 112.47\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 420      |\n",
      "|    ep_rew_mean     | -51.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 324      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 145123   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 9.15     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 145022   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 414      |\n",
      "|    ep_rew_mean     | -51.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 328      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 146624   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -154     |\n",
      "|    critic_loss     | 5.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 146523   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 418      |\n",
      "|    ep_rew_mean     | -45.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 332      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 148572   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -156     |\n",
      "|    critic_loss     | 21.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 148471   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 407      |\n",
      "|    ep_rew_mean     | -37.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 336      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 149646   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -146     |\n",
      "|    critic_loss     | 35       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 149545   |\n",
      "---------------------------------\n",
      "Evaluation at step 150000: Mean Reward = 24.44\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 385      |\n",
      "|    ep_rew_mean     | -33.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 150335   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -160     |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 150234   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 385      |\n",
      "|    ep_rew_mean     | -36.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 344      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 151969   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -148     |\n",
      "|    critic_loss     | 8.26     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 151868   |\n",
      "---------------------------------\n",
      "Evaluation at step 155000: Mean Reward = 93.45\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 394      |\n",
      "|    ep_rew_mean     | -34.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 348      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 155727   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -146     |\n",
      "|    critic_loss     | 7.94     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 155626   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 388      |\n",
      "|    ep_rew_mean     | -31.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 352      |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 157968   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 22.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 157867   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 376      |\n",
      "|    ep_rew_mean     | -21.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 356      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 159324   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 39.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 159223   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 363      |\n",
      "|    ep_rew_mean     | -16.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 159798   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 15.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 159697   |\n",
      "---------------------------------\n",
      "Evaluation at step 160000: Mean Reward = 154.07\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 356      |\n",
      "|    ep_rew_mean     | -16.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 364      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 160542   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 65.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 160441   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 357      |\n",
      "|    ep_rew_mean     | -12.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 368      |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 162311   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -136     |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 162210   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 352      |\n",
      "|    ep_rew_mean     | -6.79    |\n",
      "| time/              |          |\n",
      "|    episodes        | 372      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 163602   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -145     |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 163501   |\n",
      "---------------------------------\n",
      "Evaluation at step 165000: Mean Reward = 36.65\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 352      |\n",
      "|    ep_rew_mean     | -1.99    |\n",
      "| time/              |          |\n",
      "|    episodes        | 376      |\n",
      "|    fps             | 666      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 165001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 2.76     |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 166272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -151     |\n",
      "|    critic_loss     | 12.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 166171   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 12.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 384      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 167841   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 89.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 167740   |\n",
      "---------------------------------\n",
      "Evaluation at step 170000: Mean Reward = -112.76\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 359      |\n",
      "|    ep_rew_mean     | 21.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 388      |\n",
      "|    fps             | 484      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 170001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | 18.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 392      |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 171499   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 18.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 171398   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 350      |\n",
      "|    ep_rew_mean     | 12       |\n",
      "| time/              |          |\n",
      "|    episodes        | 396      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 172667   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -144     |\n",
      "|    critic_loss     | 19.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 172566   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 350      |\n",
      "|    ep_rew_mean     | 17.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 173421   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -142     |\n",
      "|    critic_loss     | 40.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 173320   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 18.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 404      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 174343   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -136     |\n",
      "|    critic_loss     | 17       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 174242   |\n",
      "---------------------------------\n",
      "Evaluation at step 175000: Mean Reward = -62.90\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 365      |\n",
      "|    ep_rew_mean     | 18.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 408      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 176150   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 351      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 176049   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 363      |\n",
      "|    ep_rew_mean     | 27.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 412      |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 177670   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -140     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 177569   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 371      |\n",
      "|    ep_rew_mean     | 24.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 416      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 179805   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 15.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 179704   |\n",
      "---------------------------------\n",
      "Evaluation at step 180000: Mean Reward = -45.11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 365      |\n",
      "|    ep_rew_mean     | 18.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 181142   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -141     |\n",
      "|    critic_loss     | 7.05     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 181041   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 363      |\n",
      "|    ep_rew_mean     | 13.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 424      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 181469   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -134     |\n",
      "|    critic_loss     | 21.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 181368   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 370      |\n",
      "|    ep_rew_mean     | 14.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 428      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 183653   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -137     |\n",
      "|    critic_loss     | 21.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 183552   |\n",
      "---------------------------------\n",
      "Evaluation at step 185000: Mean Reward = 61.72\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 374      |\n",
      "|    ep_rew_mean     | 13.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 432      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 186001   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -136     |\n",
      "|    critic_loss     | 21.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 185900   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 393      |\n",
      "|    ep_rew_mean     | 13.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 436      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 188910   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 188809   |\n",
      "---------------------------------\n",
      "Evaluation at step 190000: Mean Reward = 168.02\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 19.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 190334   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 190233   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 417      |\n",
      "|    ep_rew_mean     | 16.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 444      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 193708   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 17.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 193607   |\n",
      "---------------------------------\n",
      "Evaluation at step 195000: Mean Reward = 74.78\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 407      |\n",
      "|    ep_rew_mean     | 22.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 448      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 196463   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 196362   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 397      |\n",
      "|    ep_rew_mean     | 28.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 452      |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 197650   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 13.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 197549   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 405      |\n",
      "|    ep_rew_mean     | 21.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 456      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 199815   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 5.83     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 199714   |\n",
      "---------------------------------\n",
      "Evaluation at step 200000: Mean Reward = 122.55\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 414      |\n",
      "|    ep_rew_mean     | 31.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 201228   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 9.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 201127   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 426      |\n",
      "|    ep_rew_mean     | 29       |\n",
      "| time/              |          |\n",
      "|    episodes        | 464      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 203138   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 203037   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 415      |\n",
      "|    ep_rew_mean     | 32.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 468      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 203842   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -133     |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 203741   |\n",
      "---------------------------------\n",
      "Evaluation at step 205000: Mean Reward = 149.02\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 415      |\n",
      "|    ep_rew_mean     | 31.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 472      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 205091   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -131     |\n",
      "|    critic_loss     | 4.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 204990   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 421      |\n",
      "|    ep_rew_mean     | 33.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 476      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 207145   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 7.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 207044   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 421      |\n",
      "|    ep_rew_mean     | 33.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 208384   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -130     |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 208283   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 413      |\n",
      "|    ep_rew_mean     | 33.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 484      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 209128   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 293      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 209027   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 397      |\n",
      "|    ep_rew_mean     | 31.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 488      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 209669   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 78.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 209568   |\n",
      "---------------------------------\n",
      "Evaluation at step 210000: Mean Reward = 104.59\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 391      |\n",
      "|    ep_rew_mean     | 41.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 492      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 210637   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -132     |\n",
      "|    critic_loss     | 20.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 210536   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 396      |\n",
      "|    ep_rew_mean     | 52.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 496      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 212253   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 13.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 212152   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 400      |\n",
      "|    ep_rew_mean     | 53.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 213460   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -127     |\n",
      "|    critic_loss     | 7.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 213359   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 396      |\n",
      "|    ep_rew_mean     | 58.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 504      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 213972   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -129     |\n",
      "|    critic_loss     | 40.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 213871   |\n",
      "---------------------------------\n",
      "Evaluation at step 215000: Mean Reward = -160.72\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 389      |\n",
      "|    ep_rew_mean     | 58.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 508      |\n",
      "|    fps             | 492      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 215001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 381      |\n",
      "|    ep_rew_mean     | 51.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 512      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 215808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 228      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 215707   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 366      |\n",
      "|    ep_rew_mean     | 50.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 516      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 216446   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -121     |\n",
      "|    critic_loss     | 9.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 216345   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 361      |\n",
      "|    ep_rew_mean     | 58.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 217259   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -126     |\n",
      "|    critic_loss     | 22.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 217158   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | 65.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 524      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 217848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 217747   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 65.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 528      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 218714   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -128     |\n",
      "|    critic_loss     | 5.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 218613   |\n",
      "---------------------------------\n",
      "Evaluation at step 220000: Mean Reward = 95.62\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 58.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 532      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 220393   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -124     |\n",
      "|    critic_loss     | 12.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 220292   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 323      |\n",
      "|    ep_rew_mean     | 54       |\n",
      "| time/              |          |\n",
      "|    episodes        | 536      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 221212   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -126     |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 221111   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 47.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 223052   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -117     |\n",
      "|    critic_loss     | 9.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 222951   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 303      |\n",
      "|    ep_rew_mean     | 53.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 544      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 223990   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -123     |\n",
      "|    critic_loss     | 14       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 223889   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 548      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 224919   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -119     |\n",
      "|    critic_loss     | 34       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 224818   |\n",
      "---------------------------------\n",
      "Evaluation at step 225000: Mean Reward = 54.62\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 280      |\n",
      "|    ep_rew_mean     | 47.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 552      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 225613   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 9.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 225512   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 270      |\n",
      "|    ep_rew_mean     | 53.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 556      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 226863   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -118     |\n",
      "|    critic_loss     | 13.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 226762   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 265      |\n",
      "|    ep_rew_mean     | 45.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 227732   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -116     |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 227631   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 564      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 229050   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -111     |\n",
      "|    critic_loss     | 5.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 228949   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 40.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 568      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 229897   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 14.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 229796   |\n",
      "---------------------------------\n",
      "Evaluation at step 230000: Mean Reward = 16.00\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 37.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 572      |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 230740   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 25.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 230639   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 35.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 576      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 232315   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 27       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 232214   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 37       |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 233383   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 16.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 233282   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 34.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 584      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 234604   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -120     |\n",
      "|    critic_loss     | 4.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 234503   |\n",
      "---------------------------------\n",
      "Evaluation at step 235000: Mean Reward = 164.97\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 40.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 588      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 235797   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -115     |\n",
      "|    critic_loss     | 9.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 235696   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 276      |\n",
      "|    ep_rew_mean     | 44.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 592      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 238278   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 145      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 238177   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 274      |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 596      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 239670   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -114     |\n",
      "|    critic_loss     | 6.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 239569   |\n",
      "---------------------------------\n",
      "Evaluation at step 240000: Mean Reward = 176.43\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 45.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 118      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 240554   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -113     |\n",
      "|    critic_loss     | 6.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 240453   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 275      |\n",
      "|    ep_rew_mean     | 50.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 604      |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 241486   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 16.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 241385   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | 59.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 608      |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 243479   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 49.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 243378   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 288      |\n",
      "|    ep_rew_mean     | 68.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 612      |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 244627   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 112      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 244526   |\n",
      "---------------------------------\n",
      "Evaluation at step 245000: Mean Reward = 210.06\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 78.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 616      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 246302   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 5.84     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 246201   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | 77.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 247805   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 247704   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | 84.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 624      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 248921   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 10.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 248820   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 312      |\n",
      "|    ep_rew_mean     | 94.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 628      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 249898   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 298      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 249797   |\n",
      "---------------------------------\n",
      "Evaluation at step 250000: Mean Reward = 176.45\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    episodes        | 632      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 250890   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 7.32     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 250789   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 636      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 251749   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 251648   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 254131   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 254030   |\n",
      "---------------------------------\n",
      "Evaluation at step 255000: Mean Reward = 227.79\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 117      |\n",
      "| time/              |          |\n",
      "|    episodes        | 644      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 256207   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 9.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 256106   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    episodes        | 648      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 257289   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 9.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 257188   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 652      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 258229   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 13       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 258128   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 329      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 656      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 259744   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 16.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 259643   |\n",
      "---------------------------------\n",
      "Evaluation at step 260000: Mean Reward = 109.99\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 260698   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 9.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 260597   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 664      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 262297   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 7.71     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 262196   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 338      |\n",
      "|    ep_rew_mean     | 155      |\n",
      "| time/              |          |\n",
      "|    episodes        | 668      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 263654   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 263553   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    episodes        | 672      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 264192   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 264091   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 325      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 676      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 264827   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 18       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 264726   |\n",
      "---------------------------------\n",
      "Evaluation at step 265000: Mean Reward = 188.70\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 265625   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 6.8      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 265524   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 333      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 684      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 267904   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 13.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 267803   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 334      |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    episodes        | 688      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 269243   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 269142   |\n",
      "---------------------------------\n",
      "Evaluation at step 270000: Mean Reward = -80.91\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | 151      |\n",
      "| time/              |          |\n",
      "|    episodes        | 692      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 270216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 20.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 270115   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 328      |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 696      |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 272450   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 7.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 272349   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 339      |\n",
      "|    ep_rew_mean     | 153      |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 274491   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 27       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 274390   |\n",
      "---------------------------------\n",
      "Evaluation at step 275000: Mean Reward = 264.65\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 704      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 276171   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 7.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 276070   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 343      |\n",
      "|    ep_rew_mean     | 157      |\n",
      "| time/              |          |\n",
      "|    episodes        | 708      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 277807   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 13.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 277706   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 345      |\n",
      "|    ep_rew_mean     | 156      |\n",
      "| time/              |          |\n",
      "|    episodes        | 712      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 279084   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 21.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 278983   |\n",
      "---------------------------------\n",
      "Evaluation at step 280000: Mean Reward = 106.67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 158      |\n",
      "| time/              |          |\n",
      "|    episodes        | 716      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 280745   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 146      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 280644   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 354      |\n",
      "|    ep_rew_mean     | 164      |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 283172   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 15.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 283071   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 358      |\n",
      "|    ep_rew_mean     | 167      |\n",
      "| time/              |          |\n",
      "|    episodes        | 724      |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 284695   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 29.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 284594   |\n",
      "---------------------------------\n",
      "Evaluation at step 285000: Mean Reward = 153.38\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 362      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 728      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 286115   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 42.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 286014   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | 161      |\n",
      "| time/              |          |\n",
      "|    episodes        | 732      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 288057   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 42.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 287956   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 369      |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 736      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 288677   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 288576   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 354      |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 289565   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 328      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 289464   |\n",
      "---------------------------------\n",
      "Evaluation at step 290000: Mean Reward = 96.08\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 160      |\n",
      "| time/              |          |\n",
      "|    episodes        | 744      |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 291726   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 291625   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 376      |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 748      |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 294934   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 6.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 294833   |\n",
      "---------------------------------\n",
      "Evaluation at step 295000: Mean Reward = 29.61\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 372      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 752      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 295461   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 49.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 295360   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 367      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 756      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 296410   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 296309   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 365      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 297204   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 9.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 297103   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 353      |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    episodes        | 764      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 297615   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 297514   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 768      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 298075   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.9    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 297974   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 772      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 299244   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 39.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 299143   |\n",
      "---------------------------------\n",
      "Evaluation at step 300000: Mean Reward = 267.09\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 357      |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 776      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 300484   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 7.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 300383   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 369      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 302534   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 302433   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 355      |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    episodes        | 784      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 303375   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 6.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 303274   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 357      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 788      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 304919   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 8.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 304818   |\n",
      "---------------------------------\n",
      "Evaluation at step 305000: Mean Reward = 168.58\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 362      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 792      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 306464   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.1    |\n",
      "|    critic_loss     | 7.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 306363   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 356      |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 796      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 308012   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.4    |\n",
      "|    critic_loss     | 5.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 307911   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 347      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 309175   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 16.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 309074   |\n",
      "---------------------------------\n",
      "Evaluation at step 310000: Mean Reward = 123.93\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 339      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 804      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 310035   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 5.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 309934   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 333      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 808      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 311121   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 57.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 311020   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 340      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 812      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 313124   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 39.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 313023   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 337      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    episodes        | 816      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 314455   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 314354   |\n",
      "---------------------------------\n",
      "Evaluation at step 315000: Mean Reward = 254.24\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 150      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 315735   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97      |\n",
      "|    critic_loss     | 6.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 315634   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 331      |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 824      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 317818   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 6.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 317717   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 828      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 319343   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 8.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 319242   |\n",
      "---------------------------------\n",
      "Evaluation at step 320000: Mean Reward = 214.18\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 325      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 832      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 320588   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 19.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 320487   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 334      |\n",
      "|    ep_rew_mean     | 151      |\n",
      "| time/              |          |\n",
      "|    episodes        | 836      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 322033   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.4    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 321932   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 324002   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 21.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 323901   |\n",
      "---------------------------------\n",
      "Evaluation at step 325000: Mean Reward = 208.10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 345      |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 844      |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 326262   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 8.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 326161   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 323      |\n",
      "|    ep_rew_mean     | 162      |\n",
      "| time/              |          |\n",
      "|    episodes        | 848      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 327281   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.1    |\n",
      "|    critic_loss     | 6.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 327180   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 327      |\n",
      "|    ep_rew_mean     | 171      |\n",
      "| time/              |          |\n",
      "|    episodes        | 852      |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 328193   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 6.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 328092   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 333      |\n",
      "|    ep_rew_mean     | 180      |\n",
      "| time/              |          |\n",
      "|    episodes        | 856      |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 329669   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 5.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 329568   |\n",
      "---------------------------------\n",
      "Evaluation at step 330000: Mean Reward = 266.67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 184      |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 116      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 330747   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 330646   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | 191      |\n",
      "| time/              |          |\n",
      "|    episodes        | 864      |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 331806   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.5    |\n",
      "|    critic_loss     | 8.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 331705   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 201      |\n",
      "| time/              |          |\n",
      "|    episodes        | 868      |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 333180   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 20.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 333079   |\n",
      "---------------------------------\n",
      "Evaluation at step 335000: Mean Reward = 183.49\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 358      |\n",
      "|    ep_rew_mean     | 201      |\n",
      "| time/              |          |\n",
      "|    episodes        | 872      |\n",
      "|    fps             | 637      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 335001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 357      |\n",
      "|    ep_rew_mean     | 204      |\n",
      "| time/              |          |\n",
      "|    episodes        | 876      |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 336144   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.3    |\n",
      "|    critic_loss     | 17.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 336043   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 349      |\n",
      "|    ep_rew_mean     | 209      |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 337411   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 337310   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 351      |\n",
      "|    ep_rew_mean     | 203      |\n",
      "| time/              |          |\n",
      "|    episodes        | 884      |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 338483   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 338382   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 197      |\n",
      "| time/              |          |\n",
      "|    episodes        | 888      |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 339293   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 339192   |\n",
      "---------------------------------\n",
      "Evaluation at step 340000: Mean Reward = 176.35\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 338      |\n",
      "|    ep_rew_mean     | 203      |\n",
      "| time/              |          |\n",
      "|    episodes        | 892      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 340276   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 35.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 340175   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 334      |\n",
      "|    ep_rew_mean     | 203      |\n",
      "| time/              |          |\n",
      "|    episodes        | 896      |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 341456   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 12.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 341355   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 342640   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 12.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 342539   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 336      |\n",
      "|    ep_rew_mean     | 207      |\n",
      "| time/              |          |\n",
      "|    episodes        | 904      |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 343661   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 6.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 343560   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 335      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 908      |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 344586   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 88.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 344485   |\n",
      "---------------------------------\n",
      "Evaluation at step 345000: Mean Reward = 247.11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 328      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 912      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 345919   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.9    |\n",
      "|    critic_loss     | 11.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 345818   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 916      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 346853   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 18       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 346752   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 215      |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 347861   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 347760   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 216      |\n",
      "| time/              |          |\n",
      "|    episodes        | 924      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 348809   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 348708   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | 215      |\n",
      "| time/              |          |\n",
      "|    episodes        | 928      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 349759   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 11.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 349658   |\n",
      "---------------------------------\n",
      "Evaluation at step 350000: Mean Reward = 267.34\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | 215      |\n",
      "| time/              |          |\n",
      "|    episodes        | 932      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 350947   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 3.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 350846   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 936      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 352667   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 352566   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 218      |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 353470   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 353369   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 280      |\n",
      "|    ep_rew_mean     | 217      |\n",
      "| time/              |          |\n",
      "|    episodes        | 944      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 354284   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 17.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 354183   |\n",
      "---------------------------------\n",
      "Evaluation at step 355000: Mean Reward = 271.53\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 280      |\n",
      "|    ep_rew_mean     | 220      |\n",
      "| time/              |          |\n",
      "|    episodes        | 948      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 355278   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.4    |\n",
      "|    critic_loss     | 6.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 355177   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 281      |\n",
      "|    ep_rew_mean     | 219      |\n",
      "| time/              |          |\n",
      "|    episodes        | 952      |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 356318   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 8.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 356217   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 278      |\n",
      "|    ep_rew_mean     | 220      |\n",
      "| time/              |          |\n",
      "|    episodes        | 956      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 357451   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 21.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 357350   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 275      |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 358200   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 358099   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 272      |\n",
      "|    ep_rew_mean     | 226      |\n",
      "| time/              |          |\n",
      "|    episodes        | 964      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 359013   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 15       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 358912   |\n",
      "---------------------------------\n",
      "Evaluation at step 360000: Mean Reward = 247.02\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 226      |\n",
      "| time/              |          |\n",
      "|    episodes        | 968      |\n",
      "|    fps             | 653      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 360001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 972      |\n",
      "|    fps             | 148      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 360899   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 4.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 360798   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 976      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 362237   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 362136   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 257      |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 363083   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 59.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 362982   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 242      |\n",
      "| time/              |          |\n",
      "|    episodes        | 984      |\n",
      "|    fps             | 146      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 364252   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 364151   |\n",
      "---------------------------------\n",
      "Evaluation at step 365000: Mean Reward = 225.42\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 988      |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 365108   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 6.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 365007   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 992      |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 366132   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 471      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 366031   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 254      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 996      |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 366844   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 19.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 366743   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 144      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 367835   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.9    |\n",
      "|    critic_loss     | 5.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 367734   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1004     |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 368657   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 13.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 368556   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1008     |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 369312   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 6.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 369211   |\n",
      "---------------------------------\n",
      "Evaluation at step 370000: Mean Reward = 276.11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1012     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 370586   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 11.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 370485   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1016     |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 372313   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 372212   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 145      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 373207   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 4.83     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 373106   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 252      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1024     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 373967   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 373866   |\n",
      "---------------------------------\n",
      "Evaluation at step 375000: Mean Reward = 265.32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1028     |\n",
      "|    fps             | 147      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 375027   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 16.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 374926   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 249      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1032     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 375837   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 7.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 375736   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1036     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 377370   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 377269   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 254      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 378915   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 4.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 378814   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1044     |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 379858   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 7.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 379757   |\n",
      "---------------------------------\n",
      "Evaluation at step 380000: Mean Reward = 225.65\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1048     |\n",
      "|    fps             | 141      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 380751   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 380650   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1052     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 382155   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 19.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 382054   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 262      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1056     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 383700   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 17.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 383599   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 266      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 384848   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.3    |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 384747   |\n",
      "---------------------------------\n",
      "Evaluation at step 385000: Mean Reward = 209.43\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1064     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 385808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 3.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 385707   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1068     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 387106   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 3.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 387005   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1072     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 387968   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 387867   |\n",
      "---------------------------------\n",
      "Evaluation at step 390000: Mean Reward = 233.30\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 278      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1076     |\n",
      "|    fps             | 487      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 390001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 391704   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 30.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 391603   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 293      |\n",
      "|    ep_rew_mean     | 244      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1084     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 393511   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.8    |\n",
      "|    critic_loss     | 4.25     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 393410   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1088     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 394524   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 224      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 394423   |\n",
      "---------------------------------\n",
      "Evaluation at step 395000: Mean Reward = 237.96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1092     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 396704   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 17.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 396603   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 308      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1096     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 397675   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.8    |\n",
      "|    critic_loss     | 238      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 397574   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 315      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 399289   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 399188   |\n",
      "---------------------------------\n",
      "Evaluation at step 400000: Mean Reward = 257.46\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 319      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1104     |\n",
      "|    fps             | 143      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 400551   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 9.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 400450   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 329      |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1108     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 402201   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.6    |\n",
      "|    critic_loss     | 16.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 402100   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 331      |\n",
      "|    ep_rew_mean     | 236      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1112     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 403727   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 32       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 403626   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1116     |\n",
      "|    fps             | 142      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 404918   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 404817   |\n",
      "---------------------------------\n",
      "Evaluation at step 405000: Mean Reward = 231.34\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 333      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 406466   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 5.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 406365   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 341      |\n",
      "|    ep_rew_mean     | 226      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1124     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 408097   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.5    |\n",
      "|    critic_loss     | 5.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 407996   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | 221      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1128     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 409252   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.5    |\n",
      "|    critic_loss     | 7.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 409151   |\n",
      "---------------------------------\n",
      "Evaluation at step 410000: Mean Reward = 144.30\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 213      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1132     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 410287   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 9.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 410186   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 212      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1136     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 411782   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 7.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 411681   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 342      |\n",
      "|    ep_rew_mean     | 212      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 413145   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 57.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 413044   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1144     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 414216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.3    |\n",
      "|    critic_loss     | 8.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 414115   |\n",
      "---------------------------------\n",
      "Evaluation at step 415000: Mean Reward = 180.85\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 216      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1148     |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 415159   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 97.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 415058   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 343      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1152     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 416458   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.3    |\n",
      "|    critic_loss     | 3.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 416357   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 350      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1156     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 418746   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.8    |\n",
      "|    critic_loss     | 5.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 418645   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 346      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 419424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.7    |\n",
      "|    critic_loss     | 9.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 419323   |\n",
      "---------------------------------\n",
      "Evaluation at step 420000: Mean Reward = 74.00\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 344      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1164     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 420216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 420115   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 338      |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1168     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 420926   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.1    |\n",
      "|    critic_loss     | 161      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 420825   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 339      |\n",
      "|    ep_rew_mean     | 207      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1172     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 421850   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.1    |\n",
      "|    critic_loss     | 190      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 421749   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | 209      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1176     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 422972   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 9.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 422871   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 332      |\n",
      "|    ep_rew_mean     | 207      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 424860   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 13.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 424759   |\n",
      "---------------------------------\n",
      "Evaluation at step 425000: Mean Reward = 225.35\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 326      |\n",
      "|    ep_rew_mean     | 207      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1184     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 426135   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.2    |\n",
      "|    critic_loss     | 4.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 426034   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1188     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 426890   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.1    |\n",
      "|    critic_loss     | 15.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 426789   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1192     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 427734   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.7    |\n",
      "|    critic_loss     | 13.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 427633   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1196     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 428656   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.6    |\n",
      "|    critic_loss     | 4.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 428555   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 303      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 429584   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.1    |\n",
      "|    critic_loss     | 8.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 429483   |\n",
      "---------------------------------\n",
      "Evaluation at step 430000: Mean Reward = 254.52\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 214      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1204     |\n",
      "|    fps             | 137      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 430424   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 5.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 430323   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 291      |\n",
      "|    ep_rew_mean     | 218      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1208     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 431283   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.1    |\n",
      "|    critic_loss     | 4.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 431182   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | 220      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1212     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 432138   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.1    |\n",
      "|    critic_loss     | 3.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 432037   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 282      |\n",
      "|    ep_rew_mean     | 223      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1216     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 433077   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.9    |\n",
      "|    critic_loss     | 179      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 432976   |\n",
      "---------------------------------\n",
      "Evaluation at step 435000: Mean Reward = 240.69\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | 227      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 985      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 435001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 279      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1224     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 435962   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.6    |\n",
      "|    critic_loss     | 18.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 435861   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 277      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1228     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 436990   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.4    |\n",
      "|    critic_loss     | 5.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 436889   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 276      |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1232     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 437854   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.7    |\n",
      "|    critic_loss     | 5.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 437753   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1236     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 438588   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.7    |\n",
      "|    critic_loss     | 5.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 438487   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 236      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 439924   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92      |\n",
      "|    critic_loss     | 222      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 439823   |\n",
      "---------------------------------\n",
      "Evaluation at step 440000: Mean Reward = 220.22\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1244     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 441019   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.7    |\n",
      "|    critic_loss     | 6.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 440918   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 270      |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1248     |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 442205   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97      |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 442104   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 267      |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1252     |\n",
      "|    fps             | 139      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 443161   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 4.94     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 443060   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1256     |\n",
      "|    fps             | 140      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 444504   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.4    |\n",
      "|    critic_loss     | 8.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 444403   |\n",
      "---------------------------------\n",
      "Evaluation at step 445000: Mean Reward = 259.76\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 445285   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 4.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 445184   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1264     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 446292   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.3    |\n",
      "|    critic_loss     | 24.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 446191   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 265      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1268     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 447469   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.4    |\n",
      "|    critic_loss     | 8.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 447368   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 267      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1272     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 448539   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 19.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 448438   |\n",
      "---------------------------------\n",
      "Evaluation at step 450000: Mean Reward = 259.11\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1276     |\n",
      "|    fps             | 136      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 450031   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 4.67     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 449930   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 264      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 451229   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95      |\n",
      "|    critic_loss     | 86.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 451128   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 263      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1284     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 452459   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.4    |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 452358   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 277      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1288     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 454601   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 454500   |\n",
      "---------------------------------\n",
      "Evaluation at step 455000: Mean Reward = 250.51\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 281      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1292     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 455847   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.8    |\n",
      "|    critic_loss     | 3.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 455746   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1296     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 457060   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 456959   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 288      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 458379   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.2    |\n",
      "|    critic_loss     | 206      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 458278   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 292      |\n",
      "|    ep_rew_mean     | 244      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1304     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 459586   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 8.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 459485   |\n",
      "---------------------------------\n",
      "Evaluation at step 460000: Mean Reward = 247.25\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 293      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1308     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 460600   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.7    |\n",
      "|    critic_loss     | 20.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 460499   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 300      |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1312     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 462183   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.4    |\n",
      "|    critic_loss     | 4.8      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 462082   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1316     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 463323   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 3.38     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 463222   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 241      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 464497   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.3    |\n",
      "|    critic_loss     | 8.95     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 464396   |\n",
      "---------------------------------\n",
      "Evaluation at step 465000: Mean Reward = 255.97\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1324     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 465323   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.4    |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 465222   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 240      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1328     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 466384   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.3    |\n",
      "|    critic_loss     | 4.05     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 466283   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 296      |\n",
      "|    ep_rew_mean     | 243      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1332     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 467409   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 3.89     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 467308   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 298      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1336     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 468370   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 20.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 468269   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 469851   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 6.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 469750   |\n",
      "---------------------------------\n",
      "Evaluation at step 470000: Mean Reward = 256.32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 297      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1344     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 470687   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.3    |\n",
      "|    critic_loss     | 14.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 470586   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | 244      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1348     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 472257   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 9.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 472156   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1352     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 473284   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.8    |\n",
      "|    critic_loss     | 8.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 473183   |\n",
      "---------------------------------\n",
      "Evaluation at step 475000: Mean Reward = 245.93\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 243      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1356     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 475084   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.5    |\n",
      "|    critic_loss     | 13.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 474983   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 317      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 476963   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.2    |\n",
      "|    critic_loss     | 29.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 476862   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1364     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 477867   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 23       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 477766   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1368     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 479065   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.8    |\n",
      "|    critic_loss     | 15.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 478964   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 314      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1372     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 479987   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.9    |\n",
      "|    critic_loss     | 4.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 479886   |\n",
      "---------------------------------\n",
      "Evaluation at step 480000: Mean Reward = 272.67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 308      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1376     |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 480812   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 480711   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 483284   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.9    |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 483183   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 320      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1384     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 484416   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.7    |\n",
      "|    critic_loss     | 5.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 484315   |\n",
      "---------------------------------\n",
      "Evaluation at step 485000: Mean Reward = 267.07\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1388     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 485727   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 7.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 485626   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 311      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1392     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 486968   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.6    |\n",
      "|    critic_loss     | 6.75     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 486867   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 320      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1396     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 489105   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.6    |\n",
      "|    critic_loss     | 6.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 489004   |\n",
      "---------------------------------\n",
      "Evaluation at step 490000: Mean Reward = 156.23\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 629      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 490001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 313      |\n",
      "|    ep_rew_mean     | 231      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1404     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 490934   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.8    |\n",
      "|    critic_loss     | 177      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 490833   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 315      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1408     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 492110   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.1    |\n",
      "|    critic_loss     | 4.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 492009   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1412     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 494535   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 5.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 494434   |\n",
      "---------------------------------\n",
      "Evaluation at step 495000: Mean Reward = 262.13\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 323      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1416     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 495594   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.3    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 495493   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 231      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 496700   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.7    |\n",
      "|    critic_loss     | 4.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 496599   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 323      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1424     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 497588   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.4    |\n",
      "|    critic_loss     | 8.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 497487   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1428     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 498461   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 4.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 498360   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 322      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1432     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 499574   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.8    |\n",
      "|    critic_loss     | 5.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 499473   |\n",
      "---------------------------------\n",
      "Evaluation at step 500000: Mean Reward = 284.38\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 232      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1436     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 500453   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 59.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 500352   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 316      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 501440   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 3.99     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 501339   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 324      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1444     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 503042   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.3    |\n",
      "|    critic_loss     | 98.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 502941   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 317      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1448     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 503971   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.6    |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 503870   |\n",
      "---------------------------------\n",
      "Evaluation at step 505000: Mean Reward = 111.59\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 321      |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1452     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 505338   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.7    |\n",
      "|    critic_loss     | 3.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 505237   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 312      |\n",
      "|    ep_rew_mean     | 238      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1456     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 506247   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.3    |\n",
      "|    critic_loss     | 5.98     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 506146   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 302      |\n",
      "|    ep_rew_mean     | 235      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 507121   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.4    |\n",
      "|    critic_loss     | 5.15     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 507020   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 303      |\n",
      "|    ep_rew_mean     | 231      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1464     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 508151   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 7.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 508050   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 297      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1468     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 508780   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.8    |\n",
      "|    critic_loss     | 3.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 508679   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 296      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1472     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 509552   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 4.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 509451   |\n",
      "---------------------------------\n",
      "Evaluation at step 510000: Mean Reward = 265.88\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 229      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1476     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 510192   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.3    |\n",
      "|    critic_loss     | 25.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 510091   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 277      |\n",
      "|    ep_rew_mean     | 236      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 511017   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.9    |\n",
      "|    critic_loss     | 7.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 510916   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 275      |\n",
      "|    ep_rew_mean     | 237      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1484     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 511868   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.7    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 511767   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 272      |\n",
      "|    ep_rew_mean     | 243      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1488     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 512950   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 512849   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 269      |\n",
      "|    ep_rew_mean     | 243      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1492     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 513849   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.5    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 513748   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1496     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 514951   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.2    |\n",
      "|    critic_loss     | 7.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 514850   |\n",
      "---------------------------------\n",
      "Evaluation at step 515000: Mean Reward = 282.85\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 515603   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -88.1    |\n",
      "|    critic_loss     | 14.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 515502   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 257      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1504     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 516624   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.7    |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 516523   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 245      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1508     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 517363   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.8    |\n",
      "|    critic_loss     | 5.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 517262   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1512     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 518887   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.5    |\n",
      "|    critic_loss     | 17.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 518786   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1516     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 519726   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.5    |\n",
      "|    critic_loss     | 2.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 519625   |\n",
      "---------------------------------\n",
      "Evaluation at step 520000: Mean Reward = 279.85\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 238      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1520     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 520455   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 8.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 520354   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1524     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 521141   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 20.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 521040   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1528     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 522025   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.2    |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 521924   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1532     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 522956   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 6.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 522855   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1536     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 523841   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 9.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 523740   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1540     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 524748   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 3.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 524647   |\n",
      "---------------------------------\n",
      "Evaluation at step 525000: Mean Reward = 268.75\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1544     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 525561   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.8    |\n",
      "|    critic_loss     | 7.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 525460   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1548     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 526885   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 5.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 526784   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1552     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 527846   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94      |\n",
      "|    critic_loss     | 7.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 527745   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1556     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 528907   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 528806   |\n",
      "---------------------------------\n",
      "Evaluation at step 530000: Mean Reward = 262.08\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1560     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 530271   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.1    |\n",
      "|    critic_loss     | 9.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 530170   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1564     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 532535   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 4.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 532434   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1568     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 533782   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 4.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 533681   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1572     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 534862   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.7    |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 534761   |\n",
      "---------------------------------\n",
      "Evaluation at step 535000: Mean Reward = 260.01\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1576     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 535671   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 3.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 535570   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1580     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 536773   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.7    |\n",
      "|    critic_loss     | 4.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 536672   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1584     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 537688   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.3    |\n",
      "|    critic_loss     | 244      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 537587   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1588     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 538550   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93      |\n",
      "|    critic_loss     | 19.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 538449   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 256      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1592     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 539442   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.7    |\n",
      "|    critic_loss     | 11.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 539341   |\n",
      "---------------------------------\n",
      "Evaluation at step 540000: Mean Reward = 288.22\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1596     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 540246   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.5    |\n",
      "|    critic_loss     | 3.62     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 540145   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1600     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 541059   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.1    |\n",
      "|    critic_loss     | 28.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 540958   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 261      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1604     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 541947   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95      |\n",
      "|    critic_loss     | 12.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 541846   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 264      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1608     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 542827   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.9    |\n",
      "|    critic_loss     | 15.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 542726   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1612     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 543971   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 2.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 543870   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1616     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 544715   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.7    |\n",
      "|    critic_loss     | 5.39     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 544614   |\n",
      "---------------------------------\n",
      "Evaluation at step 545000: Mean Reward = 287.63\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1620     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 545435   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.7    |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 545334   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1624     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 546216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.3    |\n",
      "|    critic_loss     | 3.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 546115   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 264      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1628     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 546840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.9    |\n",
      "|    critic_loss     | 25.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 546739   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1632     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 547643   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.5    |\n",
      "|    critic_loss     | 2.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 547542   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 246      |\n",
      "|    ep_rew_mean     | 264      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1636     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 548483   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 4.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 548382   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1640     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 549128   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.6    |\n",
      "|    critic_loss     | 9.83     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 549027   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 243      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1644     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 549836   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.4    |\n",
      "|    critic_loss     | 2.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 549735   |\n",
      "---------------------------------\n",
      "Evaluation at step 550000: Mean Reward = 251.96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1648     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 550557   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.5    |\n",
      "|    critic_loss     | 2.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 550456   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1652     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 551301   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 31       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 551200   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1656     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 552003   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.4    |\n",
      "|    critic_loss     | 5.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 551902   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1660     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 552749   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 3.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 552648   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 211      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1664     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 553615   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.3    |\n",
      "|    critic_loss     | 18       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 553514   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1668     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 554673   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.7    |\n",
      "|    critic_loss     | 1.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 554572   |\n",
      "---------------------------------\n",
      "Evaluation at step 555000: Mean Reward = 285.68\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1672     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 555385   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 7.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 555284   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1676     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 556160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 7.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 556059   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1680     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 556885   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.5    |\n",
      "|    critic_loss     | 17.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 556784   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1684     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 557737   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.4    |\n",
      "|    critic_loss     | 10.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 557636   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1688     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 558489   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.4    |\n",
      "|    critic_loss     | 7.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 558388   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1692     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 559429   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 2.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 559328   |\n",
      "---------------------------------\n",
      "Evaluation at step 560000: Mean Reward = 283.44\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1696     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 560549   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 3.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 560448   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1700     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 561318   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 5.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 561217   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1704     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 562089   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89.8    |\n",
      "|    critic_loss     | 61.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 561988   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1708     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 562895   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 7.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 562794   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1712     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 563644   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 182      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 563543   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1716     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 564455   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 15.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 564354   |\n",
      "---------------------------------\n",
      "Evaluation at step 565000: Mean Reward = 262.39\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1720     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 565166   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.4    |\n",
      "|    critic_loss     | 2.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 565065   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1724     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 565946   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 9.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 565845   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1728     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 567162   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.7    |\n",
      "|    critic_loss     | 11.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 567061   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1732     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 567995   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.7    |\n",
      "|    critic_loss     | 7.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 567894   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1736     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 568777   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.2    |\n",
      "|    critic_loss     | 21.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 568676   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1740     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 569668   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.8    |\n",
      "|    critic_loss     | 1.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 569567   |\n",
      "---------------------------------\n",
      "Evaluation at step 570000: Mean Reward = 289.65\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1744     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 570451   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.4    |\n",
      "|    critic_loss     | 8.69     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 570350   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1748     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 571324   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 3.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 571223   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1752     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 572085   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.9    |\n",
      "|    critic_loss     | 2.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 571984   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1756     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 572898   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.1    |\n",
      "|    critic_loss     | 14.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 572797   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1760     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 573710   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 8.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 573609   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1764     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 574434   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.7    |\n",
      "|    critic_loss     | 8.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 574333   |\n",
      "---------------------------------\n",
      "Evaluation at step 575000: Mean Reward = 273.74\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1768     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 575425   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.5    |\n",
      "|    critic_loss     | 6.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 575324   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1772     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 576045   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.9    |\n",
      "|    critic_loss     | 4.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 575944   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1776     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 576777   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.7    |\n",
      "|    critic_loss     | 13       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 576676   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1780     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 578250   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.6    |\n",
      "|    critic_loss     | 7.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 578149   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1784     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 579078   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 5.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 578977   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 264      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1788     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 579884   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.8    |\n",
      "|    critic_loss     | 6.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 579783   |\n",
      "---------------------------------\n",
      "Evaluation at step 580000: Mean Reward = 265.66\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 212      |\n",
      "|    ep_rew_mean     | 263      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1792     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 580593   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 3.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 580492   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1796     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 581216   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 30.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 581115   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1800     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 582230   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.5    |\n",
      "|    critic_loss     | 13.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 582129   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1804     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 582898   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.6    |\n",
      "|    critic_loss     | 4.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 582797   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1808     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 583617   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 5.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 583516   |\n",
      "---------------------------------\n",
      "Evaluation at step 585000: Mean Reward = 232.54\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1812     |\n",
      "|    fps             | 573      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 585001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1816     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 585753   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 585652   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 221      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1820     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 587242   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 3.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 587141   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1824     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 588251   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.4    |\n",
      "|    critic_loss     | 8.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 588150   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 220      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1828     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 589204   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 5.71     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 589103   |\n",
      "---------------------------------\n",
      "Evaluation at step 590000: Mean Reward = 265.14\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 220      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1832     |\n",
      "|    fps             | 389      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 590001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1836     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 591120   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 591019   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 224      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1840     |\n",
      "|    fps             | 122      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 592066   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 591965   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1844     |\n",
      "|    fps             | 114      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 593197   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 38       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 593096   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1848     |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 594004   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 4.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 593903   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1852     |\n",
      "|    fps             | 113      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 594838   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 6.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 594737   |\n",
      "---------------------------------\n",
      "Evaluation at step 595000: Mean Reward = 266.79\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1856     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 595562   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 19.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 595461   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1860     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 596534   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 15.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 596433   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 230      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1864     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 597446   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 3.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 597345   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1868     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 598564   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 598463   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1872     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 599448   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 4.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 599347   |\n",
      "---------------------------------\n",
      "Evaluation at step 600000: Mean Reward = 228.84\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 238      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1876     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 600574   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 21       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 600473   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1880     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 601646   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.5    |\n",
      "|    critic_loss     | 6.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 601545   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 265      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1884     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 602446   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.1    |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 602345   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 240      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1888     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 603868   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.8    |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 603767   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1892     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 604735   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 14       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 604634   |\n",
      "---------------------------------\n",
      "Evaluation at step 605000: Mean Reward = 256.17\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1896     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 605628   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.3    |\n",
      "|    critic_loss     | 109      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 605527   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1900     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 607266   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 607165   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1904     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 607971   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 6.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 607870   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 261      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1908     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 608701   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 2.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 608600   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 264      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1912     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 609360   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 10.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 609259   |\n",
      "---------------------------------\n",
      "Evaluation at step 610000: Mean Reward = 243.82\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1916     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 610527   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.3      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 610426   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 242      |\n",
      "|    ep_rew_mean     | 263      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1920     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 611441   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 611340   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1924     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 613077   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 612976   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 246      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1928     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 613805   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.89     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 613704   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1932     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 614442   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 5.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 614341   |\n",
      "---------------------------------\n",
      "Evaluation at step 615000: Mean Reward = 90.41\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 243      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1936     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 615181   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 5.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 615080   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 234      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1940     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 616206   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 6.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 616105   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 227      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1944     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 616926   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 5.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 616825   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 222      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1948     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 617418   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 617317   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | 217      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1952     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 618053   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 3.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 617952   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 211      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1956     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 619050   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 618949   |\n",
      "---------------------------------\n",
      "Evaluation at step 620000: Mean Reward = 180.61\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 243      |\n",
      "|    ep_rew_mean     | 206      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1960     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 620817   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.36     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 620716   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 200      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1964     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 621537   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 5.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 621436   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 194      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1968     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 622148   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 22.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 622047   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 184      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1972     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 624266   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 12.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 624165   |\n",
      "---------------------------------\n",
      "Evaluation at step 625000: Mean Reward = 209.53\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1976     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 626492   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 4.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 626391   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 175      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1980     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 627786   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 16.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 627685   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 172      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1984     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 628575   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 628474   |\n",
      "---------------------------------\n",
      "Evaluation at step 630000: Mean Reward = 242.68\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 270      |\n",
      "|    ep_rew_mean     | 175      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1988     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 630874   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 630773   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 269      |\n",
      "|    ep_rew_mean     | 174      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1992     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 631610   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 20.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 631509   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 269      |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1996     |\n",
      "|    fps             | 124      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 632555   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 2.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 632454   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 267      |\n",
      "|    ep_rew_mean     | 177      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2000     |\n",
      "|    fps             | 123      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 633921   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 53.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 633820   |\n",
      "---------------------------------\n",
      "Evaluation at step 635000: Mean Reward = 262.32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 272      |\n",
      "|    ep_rew_mean     | 177      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2004     |\n",
      "|    fps             | 124      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 635204   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 635103   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 283      |\n",
      "|    ep_rew_mean     | 178      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2008     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 637034   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 26.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 636933   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 291      |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2012     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 638494   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 638393   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 289      |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2016     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 639444   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 639343   |\n",
      "---------------------------------\n",
      "Evaluation at step 640000: Mean Reward = 188.58\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2020     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 640031   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 77.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 639930   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 281      |\n",
      "|    ep_rew_mean     | 173      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2024     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 641152   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 3.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 641051   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 282      |\n",
      "|    ep_rew_mean     | 176      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2028     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 641966   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 641865   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 289      |\n",
      "|    ep_rew_mean     | 183      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2032     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 643383   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 1.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 643282   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 298      |\n",
      "|    ep_rew_mean     | 190      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2036     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 644965   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 7.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 644864   |\n",
      "---------------------------------\n",
      "Evaluation at step 645000: Mean Reward = 272.10\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | 197      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2040     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 646351   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.4    |\n",
      "|    critic_loss     | 6.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 646250   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | 204      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2044     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 647313   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.3    |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 647212   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 310      |\n",
      "|    ep_rew_mean     | 210      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2048     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 648399   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 19       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 648298   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 314      |\n",
      "|    ep_rew_mean     | 216      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2052     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 649446   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 6.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 649345   |\n",
      "---------------------------------\n",
      "Evaluation at step 650000: Mean Reward = 215.17\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 317      |\n",
      "|    ep_rew_mean     | 222      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2056     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 650723   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 14       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 650622   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 226      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2060     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 651405   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.5    |\n",
      "|    critic_loss     | 8.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 651304   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 307      |\n",
      "|    ep_rew_mean     | 233      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2064     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 652203   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 4.92     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 652102   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 309      |\n",
      "|    ep_rew_mean     | 239      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2068     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 653038   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 652937   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | 246      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2072     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 654643   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 654542   |\n",
      "---------------------------------\n",
      "Evaluation at step 655000: Mean Reward = 215.73\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2076     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 656400   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 23.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 656299   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2080     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 657206   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 7.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 657105   |\n",
      "---------------------------------\n",
      "Evaluation at step 660000: Mean Reward = 246.01\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 314      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2084     |\n",
      "|    fps             | 323      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 660001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 300      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2088     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 660884   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.3    |\n",
      "|    critic_loss     | 7.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 660783   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 299      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2092     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 661557   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 5        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 661456   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 305      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2096     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 663103   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 663002   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 306      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2100     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 664561   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 8.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 664460   |\n",
      "---------------------------------\n",
      "Evaluation at step 665000: Mean Reward = 225.89\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 304      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2104     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 665557   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 3.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 665456   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 301      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2108     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 667131   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 14.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 667030   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 293      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2112     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 667828   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 6.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 667727   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 292      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2116     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 668679   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 668578   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 294      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2120     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 669461   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 7.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 669360   |\n",
      "---------------------------------\n",
      "Evaluation at step 670000: Mean Reward = 269.01\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 288      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2124     |\n",
      "|    fps             | 394      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 670001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 291      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2128     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 671115   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 51.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 671014   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2132     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 672903   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 9        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 672802   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2136     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 674452   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.8    |\n",
      "|    critic_loss     | 7.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 674351   |\n",
      "---------------------------------\n",
      "Evaluation at step 675000: Mean Reward = 280.27\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 286      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2140     |\n",
      "|    fps             | 490      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 675001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 285      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2144     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 675824   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -90.9    |\n",
      "|    critic_loss     | 16.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 675723   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 290      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2148     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 677366   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 677265   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 303      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2152     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 679768   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 3.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 679667   |\n",
      "---------------------------------\n",
      "Evaluation at step 680000: Mean Reward = 273.75\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 297      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2156     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 680419   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 2.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 680318   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 296      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2160     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 681045   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 3.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 680944   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 296      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2164     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 681776   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.5    |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 681675   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 295      |\n",
      "|    ep_rew_mean     | 248      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2168     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 682553   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 3.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 682452   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 288      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2172     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 683422   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 11.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 683321   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 278      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2176     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 684198   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 684097   |\n",
      "---------------------------------\n",
      "Evaluation at step 685000: Mean Reward = 259.25\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 280      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2180     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 685156   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 9.92     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 685055   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 260      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2184     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 686017   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 5.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 685916   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 267      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2188     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 687542   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 7.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 687441   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 277      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2192     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 689270   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 3.58     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 689169   |\n",
      "---------------------------------\n",
      "Evaluation at step 690000: Mean Reward = 246.64\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 271      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2196     |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 690214   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.6    |\n",
      "|    critic_loss     | 3.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 690113   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 264      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2200     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 690930   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 4.56     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 690829   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | 247      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2204     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 692403   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 4.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 692302   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 260      |\n",
      "|    ep_rew_mean     | 250      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2208     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 693181   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 12.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 693080   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2212     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 693963   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 2.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 693862   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 260      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2216     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 694675   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 26.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 694574   |\n",
      "---------------------------------\n",
      "Evaluation at step 695000: Mean Reward = 277.56\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 261      |\n",
      "|    ep_rew_mean     | 249      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2220     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 695515   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 2.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 695414   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 263      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2224     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 696264   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 2.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 696163   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 259      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2228     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 696996   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.9    |\n",
      "|    critic_loss     | 10.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 696895   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2232     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 697753   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 697652   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 240      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2236     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 698476   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 20.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 698375   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 249      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2240     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 699949   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 22.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 699848   |\n",
      "---------------------------------\n",
      "Evaluation at step 700000: Mean Reward = 254.08\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 251      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2244     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 700614   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.7    |\n",
      "|    critic_loss     | 18       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 700513   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2248     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 701489   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -91.3    |\n",
      "|    critic_loss     | 5.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 701388   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2252     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 703105   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.4    |\n",
      "|    critic_loss     | 23.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 703004   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2256     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 703846   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 22.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 703745   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2260     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 704595   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 704494   |\n",
      "---------------------------------\n",
      "Evaluation at step 705000: Mean Reward = 281.67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2264     |\n",
      "|    fps             | 124      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 705272   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 705171   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2268     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 705956   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 10.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 705855   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2272     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 706629   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97      |\n",
      "|    critic_loss     | 19       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 706528   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2276     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 708260   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.5    |\n",
      "|    critic_loss     | 6.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 708159   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2280     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 709269   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 2.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 709168   |\n",
      "---------------------------------\n",
      "Evaluation at step 710000: Mean Reward = 196.89\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2284     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 710373   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.8    |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 710272   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2288     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 711896   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 4.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 711795   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 238      |\n",
      "|    ep_rew_mean     | 259      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2292     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 713076   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 34.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 712975   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2296     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 713821   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 713720   |\n",
      "---------------------------------\n",
      "Evaluation at step 715000: Mean Reward = 270.21\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 243      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2300     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 715190   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.9    |\n",
      "|    critic_loss     | 6.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 715089   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2304     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 716075   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 715974   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2308     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 716808   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.8    |\n",
      "|    critic_loss     | 3.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 716707   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 260      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2312     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 717439   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 9.05     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 717338   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 248      |\n",
      "|    ep_rew_mean     | 258      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2316     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 719427   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.6    |\n",
      "|    critic_loss     | 2.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 719326   |\n",
      "---------------------------------\n",
      "Evaluation at step 720000: Mean Reward = 277.16\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 247      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2320     |\n",
      "|    fps             | 120      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 720183   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 9.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 720082   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 246      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2324     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 720876   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.1    |\n",
      "|    critic_loss     | 7.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 720775   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 253      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2328     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 722097   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.2    |\n",
      "|    critic_loss     | 3.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 721996   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2332     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 722902   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 9.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 722801   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 252      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2336     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 723943   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 723842   |\n",
      "---------------------------------\n",
      "Evaluation at step 725000: Mean Reward = 279.21\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 251      |\n",
      "|    ep_rew_mean     | 254      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2340     |\n",
      "|    fps             | 656      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 725001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 254      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2344     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 725967   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.6    |\n",
      "|    critic_loss     | 2.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 725866   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2348     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 727293   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 25       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 727192   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2352     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 728425   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 11.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 728324   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 254      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2356     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 729261   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 7.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 729160   |\n",
      "---------------------------------\n",
      "Evaluation at step 730000: Mean Reward = 282.32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 254      |\n",
      "|    ep_rew_mean     | 255      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2360     |\n",
      "|    fps             | 487      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 730001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 255      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2364     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 730755   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -87.7    |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 730654   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 257      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2368     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 731700   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.3    |\n",
      "|    critic_loss     | 3.3      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 731599   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 258      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2372     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 732455   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 732354   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 250      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2376     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 733277   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.84     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 733176   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 249      |\n",
      "|    ep_rew_mean     | 256      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2380     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 734133   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -89      |\n",
      "|    critic_loss     | 3.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 734032   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 244      |\n",
      "|    ep_rew_mean     | 257      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2384     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 734805   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 16.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 734704   |\n",
      "---------------------------------\n",
      "Evaluation at step 735000: Mean Reward = 272.30\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 261      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2388     |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 735604   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.9    |\n",
      "|    critic_loss     | 12.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 735503   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 262      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2392     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 736576   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 4.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 736475   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 266      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2396     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 737490   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.1    |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 737389   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 230      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2400     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 738159   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.6    |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 738058   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2404     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 738841   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.5    |\n",
      "|    critic_loss     | 33.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 738740   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2408     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 739869   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.4    |\n",
      "|    critic_loss     | 2.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 739768   |\n",
      "---------------------------------\n",
      "Evaluation at step 740000: Mean Reward = 291.33\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2412     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 740606   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.9    |\n",
      "|    critic_loss     | 5.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 740505   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 219      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2416     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 741294   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 9.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 741193   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 217      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2420     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 741918   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 741817   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 218      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2424     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 742663   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 5.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 742562   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2428     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 743388   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.5    |\n",
      "|    critic_loss     | 189      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 743287   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2432     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 744163   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 64.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 744062   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2436     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 744973   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.9    |\n",
      "|    critic_loss     | 11.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 744872   |\n",
      "---------------------------------\n",
      "Evaluation at step 745000: Mean Reward = 284.05\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2440     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 745548   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 25.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 745447   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2444     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 746260   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.8    |\n",
      "|    critic_loss     | 4.3      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 746159   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2448     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 746980   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 15.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 746879   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2452     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 747972   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 747871   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2456     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 748789   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 4.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 748688   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2460     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 749743   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 12.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 749642   |\n",
      "---------------------------------\n",
      "Evaluation at step 750000: Mean Reward = 259.74\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2464     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 750531   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.6    |\n",
      "|    critic_loss     | 1.99     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 750430   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2468     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 751319   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.2      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 751218   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2472     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 752075   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 4.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 751974   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2476     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 752745   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.3    |\n",
      "|    critic_loss     | 2.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 752644   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2480     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 753422   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.2    |\n",
      "|    critic_loss     | 16.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 753321   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2484     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 754194   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 2.75     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 754093   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2488     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 754996   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.7    |\n",
      "|    critic_loss     | 12       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 754895   |\n",
      "---------------------------------\n",
      "Evaluation at step 755000: Mean Reward = 283.40\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2492     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 755625   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.7    |\n",
      "|    critic_loss     | 13.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 755524   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2496     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 756454   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 756353   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2500     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 757211   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 31.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 757110   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2504     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 757931   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96.2    |\n",
      "|    critic_loss     | 4.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 757830   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2508     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 758910   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 8.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 758809   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2512     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 759622   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.1    |\n",
      "|    critic_loss     | 3.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 759521   |\n",
      "---------------------------------\n",
      "Evaluation at step 760000: Mean Reward = 294.51\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2516     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 760189   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.3    |\n",
      "|    critic_loss     | 4.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 760088   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 267      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2520     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 760842   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.6    |\n",
      "|    critic_loss     | 7.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 760741   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2524     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 761478   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 2.36     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 761377   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2528     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 762221   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 762120   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2532     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 762840   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.4    |\n",
      "|    critic_loss     | 17.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 762739   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 268      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2536     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 763511   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 3.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 763410   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2540     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 764327   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 764226   |\n",
      "---------------------------------\n",
      "Evaluation at step 765000: Mean Reward = 285.52\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2544     |\n",
      "|    fps             | 138      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 765026   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -92.6    |\n",
      "|    critic_loss     | 3.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 764925   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2548     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 765754   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 6.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 765653   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2552     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 766435   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 8.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 766334   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2556     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 767135   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 10.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 767034   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2560     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 768065   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 767964   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 183      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2564     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 768815   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 7.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 768714   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2568     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 769993   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 4.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 769892   |\n",
      "---------------------------------\n",
      "Evaluation at step 770000: Mean Reward = 287.32\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2572     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 770520   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 6.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 770419   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2576     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 771361   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 46.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 771260   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2580     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 772030   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 771929   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2584     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 772753   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 4.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 772652   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2588     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 773443   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 773342   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2592     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 774140   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 774039   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2596     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 774814   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 1.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 774713   |\n",
      "---------------------------------\n",
      "Evaluation at step 775000: Mean Reward = 280.23\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 182      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2600     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 775377   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 775276   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 181      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2604     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 776059   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 15       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 775958   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2608     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 776765   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 8.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 776664   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 178      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2612     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 777419   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.94     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 777318   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 179      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2616     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 778076   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 777975   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2620     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 778804   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 28.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 778703   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 181      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2624     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 779546   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.11     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 779445   |\n",
      "---------------------------------\n",
      "Evaluation at step 780000: Mean Reward = 286.16\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2628     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 780243   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 780142   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2632     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 781749   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 7.75     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 781648   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2636     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 782539   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 782438   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2640     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 783197   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 2.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 783096   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2644     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 783938   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -94.1    |\n",
      "|    critic_loss     | 9.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 783837   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2648     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 784607   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 784506   |\n",
      "---------------------------------\n",
      "Evaluation at step 785000: Mean Reward = 286.25\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2652     |\n",
      "|    fps             | 123      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 785238   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 1.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 785137   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2656     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 785880   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 1.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 785779   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2660     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 786604   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 3.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 786503   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2664     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 787323   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 8.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 787222   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2668     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 788589   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 142      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 788488   |\n",
      "---------------------------------\n",
      "Evaluation at step 790000: Mean Reward = 280.53\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2672     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 790026   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 44.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 789925   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2676     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 790761   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 7.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 790660   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2680     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 791657   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98      |\n",
      "|    critic_loss     | 9.75     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 791556   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2684     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 792564   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 792463   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2688     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 793284   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 793183   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2692     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 793963   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 8.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 793862   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2696     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 794684   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.98     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 794583   |\n",
      "---------------------------------\n",
      "Evaluation at step 795000: Mean Reward = 262.73\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2700     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 795411   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 6.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 795310   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2704     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 796137   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 796036   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2708     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 797091   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.5    |\n",
      "|    critic_loss     | 11.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 796990   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2712     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 797831   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 10.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 797730   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2716     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 798732   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 9.84     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 798631   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2720     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 799474   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 4.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 799373   |\n",
      "---------------------------------\n",
      "Evaluation at step 800000: Mean Reward = 294.67\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2724     |\n",
      "|    fps             | 382      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 800001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2728     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 800777   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 1.98     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 800676   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2732     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 801437   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 801336   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2736     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 802105   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 8.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 802004   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2740     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 802914   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 196      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 802813   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2744     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 803562   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 4.83     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 803461   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2748     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 804267   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 804166   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2752     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 804926   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 23.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 804825   |\n",
      "---------------------------------\n",
      "Evaluation at step 805000: Mean Reward = 286.62\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2756     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 805642   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.2    |\n",
      "|    critic_loss     | 1.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 805541   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2760     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 806699   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 806598   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2764     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 807429   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.8      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 807328   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2768     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 808893   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 17.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 808792   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2772     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 809706   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.2    |\n",
      "|    critic_loss     | 22.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 809605   |\n",
      "---------------------------------\n",
      "Evaluation at step 810000: Mean Reward = 281.97\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2776     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 810605   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.6    |\n",
      "|    critic_loss     | 4.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 810504   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2780     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 811315   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 56.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 811214   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2784     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 812043   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 6.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 811942   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2788     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 812748   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 812647   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2792     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 813440   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.5    |\n",
      "|    critic_loss     | 13.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 813339   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2796     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 814150   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 20.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 814049   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2800     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 814935   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.9    |\n",
      "|    critic_loss     | 6.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 814834   |\n",
      "---------------------------------\n",
      "Evaluation at step 815000: Mean Reward = 288.91\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2804     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 815650   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 12.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 815549   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2808     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 816385   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 816284   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2812     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 817122   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 13.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 817021   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2816     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 817807   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 817706   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2820     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 818586   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 818485   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2824     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 819543   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 819442   |\n",
      "---------------------------------\n",
      "Evaluation at step 820000: Mean Reward = 282.73\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2828     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 820182   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 7.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 820081   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2832     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 820972   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 820871   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2836     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 821664   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 13.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 821563   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2840     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 822511   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 7.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 822410   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2844     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 823296   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 14.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 823195   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2848     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 824061   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 823960   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2852     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 824943   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 824842   |\n",
      "---------------------------------\n",
      "Evaluation at step 825000: Mean Reward = 273.14\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2856     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 825579   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 3.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 825478   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2860     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 826326   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 2.73     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 826225   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2864     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 827164   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 5.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 827063   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2868     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 828253   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 1.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 828152   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2872     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 828960   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.8    |\n",
      "|    critic_loss     | 6.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 828859   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2876     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 829686   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 16.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 829585   |\n",
      "---------------------------------\n",
      "Evaluation at step 830000: Mean Reward = 284.89\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2880     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 830332   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 830231   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2884     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 831043   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 11.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 830942   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2888     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 831836   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 6.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 831735   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2892     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 832482   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.38     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 832381   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2896     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 833238   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 3.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 833137   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2900     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 833940   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 833839   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 190      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2904     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 834630   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.9      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 834529   |\n",
      "---------------------------------\n",
      "Evaluation at step 835000: Mean Reward = 288.39\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2908     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 835267   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 9.57     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 835166   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2912     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 835984   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.8    |\n",
      "|    critic_loss     | 6.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 835883   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2916     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 836730   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 27       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 836629   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 189      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2920     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 837447   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 6.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 837346   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2924     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 838150   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 838049   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2928     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 838923   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 838822   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2932     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 839656   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 839555   |\n",
      "---------------------------------\n",
      "Evaluation at step 840000: Mean Reward = 300.74\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2936     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 840202   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 5.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 840101   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2940     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 840975   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 36       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 840874   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 184      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2944     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 841723   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.7    |\n",
      "|    critic_loss     | 1.99     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 841622   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2948     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 842533   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 6.94     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 842432   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2952     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 843607   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 12.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 843506   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 188      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2956     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 844387   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 844286   |\n",
      "---------------------------------\n",
      "Evaluation at step 845000: Mean Reward = 273.06\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2960     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 845040   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.9    |\n",
      "|    critic_loss     | 7.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 844939   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2964     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 845741   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.83     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 845640   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2968     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 846874   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 30.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 846773   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2972     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 847564   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 1.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 847463   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 185      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2976     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 848223   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 1.25     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 848122   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2980     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 848933   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 15.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 848832   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 187      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2984     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 849720   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 3.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 849619   |\n",
      "---------------------------------\n",
      "Evaluation at step 850000: Mean Reward = 286.48\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 186      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2988     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 850387   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -96      |\n",
      "|    critic_loss     | 17.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 850286   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 191      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2992     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 851625   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 10.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 851524   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 192      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 2996     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 852451   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 3.36     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 852350   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3000     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 853332   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 853231   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3004     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 854150   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 15.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 854049   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3008     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 854899   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 854798   |\n",
      "---------------------------------\n",
      "Evaluation at step 855000: Mean Reward = 260.27\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3012     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 855524   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 4        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 855423   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3016     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 856341   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.57     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 856240   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3020     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 857124   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 18       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 857023   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3024     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 857912   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 9.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 857811   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3028     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 858673   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 72.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 858572   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3032     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 859374   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 859273   |\n",
      "---------------------------------\n",
      "Evaluation at step 860000: Mean Reward = 284.87\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3036     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 860047   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 859946   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3040     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 860767   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 8.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 860666   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3044     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 861517   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 861416   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3048     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 862203   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 3.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 862102   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3052     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 862922   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 3.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 862821   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3056     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 863691   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 863590   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3060     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 864394   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 3.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 864293   |\n",
      "---------------------------------\n",
      "Evaluation at step 865000: Mean Reward = 267.12\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3064     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 865560   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 865459   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3068     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 866328   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 2.8      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 866227   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3072     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 867182   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 7.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 867081   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3076     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 868036   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97      |\n",
      "|    critic_loss     | 2.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 867935   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3080     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 868755   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 105      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 868654   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3084     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 869581   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.93     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 869480   |\n",
      "---------------------------------\n",
      "Evaluation at step 870000: Mean Reward = 284.31\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3088     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 870187   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 870086   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3092     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 871012   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 16       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 870911   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3096     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 871982   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 2.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 871881   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3100     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 872699   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -112     |\n",
      "|    critic_loss     | 2.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 872598   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 194      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3104     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 873512   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 10.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 873411   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3108     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 874728   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 4        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 874627   |\n",
      "---------------------------------\n",
      "Evaluation at step 875000: Mean Reward = 278.05\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3112     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 875454   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 9.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 875353   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3116     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 876227   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 876126   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3120     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 877046   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 876945   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3124     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 877851   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.4    |\n",
      "|    critic_loss     | 95.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 877750   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3128     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 878718   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 878617   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3132     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 879494   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 879393   |\n",
      "---------------------------------\n",
      "Evaluation at step 880000: Mean Reward = 283.23\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3136     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 880195   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 1.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 880094   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3140     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 881107   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 4.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 881006   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3144     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 881934   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.22     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 881833   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3148     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 882640   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 3.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 882539   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3152     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 883950   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 3.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 883849   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3156     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 884674   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 7.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 884573   |\n",
      "---------------------------------\n",
      "Evaluation at step 885000: Mean Reward = 294.96\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 211      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3160     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 885523   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.8    |\n",
      "|    critic_loss     | 2.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 885422   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3164     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 886164   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -109     |\n",
      "|    critic_loss     | 3.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 886063   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3168     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 887197   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 11.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 887096   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3172     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 888158   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -108     |\n",
      "|    critic_loss     | 3.92     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 888057   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 209      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3176     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 888915   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 38       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 888814   |\n",
      "---------------------------------\n",
      "Evaluation at step 890000: Mean Reward = 283.89\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3180     |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 890173   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 2.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 890072   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3184     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 890944   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 4.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 890843   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 215      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3188     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 891665   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 3.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 891564   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3192     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 892421   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 17.8     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 892320   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 211      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3196     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 893118   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.95     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 893017   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 211      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3200     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 893839   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 2.2      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 893738   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 212      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3204     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 894665   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 3.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 894564   |\n",
      "---------------------------------\n",
      "Evaluation at step 895000: Mean Reward = 276.53\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3208     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 895352   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 895251   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3212     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 896035   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 2.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 895934   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3216     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 896929   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.7    |\n",
      "|    critic_loss     | 1.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 896828   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3220     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 897728   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 8.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 897627   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 208      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3224     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 898627   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.1    |\n",
      "|    critic_loss     | 2.39     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 898526   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3228     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 899273   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.9    |\n",
      "|    critic_loss     | 6.17     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 899172   |\n",
      "---------------------------------\n",
      "Evaluation at step 900000: Mean Reward = 254.18\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3232     |\n",
      "|    fps             | 972      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 900001   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3236     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 900844   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.5    |\n",
      "|    critic_loss     | 8.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 900743   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3240     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 901454   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 6.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 901353   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3244     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 16       |\n",
      "|    total_timesteps | 902212   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 4.15     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 902111   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3248     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 902985   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.6    |\n",
      "|    critic_loss     | 25       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 902884   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3252     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 903963   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.5    |\n",
      "|    critic_loss     | 5.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 903862   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3256     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 904669   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.8    |\n",
      "|    critic_loss     | 9.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 904568   |\n",
      "---------------------------------\n",
      "Evaluation at step 905000: Mean Reward = 267.52\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3260     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 905528   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.5    |\n",
      "|    critic_loss     | 5.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 905427   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 203      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3264     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 906420   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 3.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 906319   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 210      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3268     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 908219   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 20.6     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 908118   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3272     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 909476   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 10.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 909375   |\n",
      "---------------------------------\n",
      "Evaluation at step 910000: Mean Reward = 280.24\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 214      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3276     |\n",
      "|    fps             | 135      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 910324   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.2    |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 910223   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 216      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3280     |\n",
      "|    fps             | 133      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 911743   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.3    |\n",
      "|    critic_loss     | 2.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 911642   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 216      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3284     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 912582   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 912481   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3288     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 913943   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 7.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 913842   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 224      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3292     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 914783   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.2    |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 914682   |\n",
      "---------------------------------\n",
      "Evaluation at step 915000: Mean Reward = 279.80\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3296     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 915588   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 9.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 915487   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3300     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 916337   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 12.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 916236   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3304     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 917318   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 917217   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3308     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 918160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 918059   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 230      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3312     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 919010   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.9    |\n",
      "|    critic_loss     | 2.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 918909   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3316     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 919813   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 128      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 919712   |\n",
      "---------------------------------\n",
      "Evaluation at step 920000: Mean Reward = 275.06\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3320     |\n",
      "|    fps             | 134      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 920395   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 4.25     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 920294   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3324     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 921143   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 12.3     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 921042   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 226      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3328     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 921854   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 16.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 921753   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3332     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 922660   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 18.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 922559   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 225      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3336     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 923379   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 923278   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 226      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3340     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 924099   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 8.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 923998   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 226      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3344     |\n",
      "|    fps             | 125      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 924794   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 14.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 924693   |\n",
      "---------------------------------\n",
      "Evaluation at step 925000: Mean Reward = 281.45\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 229      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3348     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 925836   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -110     |\n",
      "|    critic_loss     | 5.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 925735   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3352     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 926659   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.6    |\n",
      "|    critic_loss     | 2.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 926558   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 228      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3356     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 927470   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 927369   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3360     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 25       |\n",
      "|    total_timesteps | 928270   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 2.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 928169   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 227      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3364     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 929109   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.42     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 929008   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 217      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3368     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 929961   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 25.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 929860   |\n",
      "---------------------------------\n",
      "Evaluation at step 930000: Mean Reward = 290.62\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3372     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 930752   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 3.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 930651   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3376     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 931579   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 931478   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 205      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3380     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 932211   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 7.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 932110   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 204      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3384     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 932975   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 17.1     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 932874   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 198      |\n",
      "|    ep_rew_mean     | 278      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3388     |\n",
      "|    fps             | 130      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 933695   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 1.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 933594   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 279      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3392     |\n",
      "|    fps             | 129      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 934391   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 299      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 934290   |\n",
      "---------------------------------\n",
      "Evaluation at step 935000: Mean Reward = 277.72\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3396     |\n",
      "|    fps             | 131      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 935215   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 23.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 935114   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3400     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 936242   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 3.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 936141   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3404     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 936946   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 31.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 936845   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 196      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3408     |\n",
      "|    fps             | 123      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 937777   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -98.3    |\n",
      "|    critic_loss     | 12.9     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 937676   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3412     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 938461   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 15.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 938360   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 193      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3416     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 939143   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 7.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 939042   |\n",
      "---------------------------------\n",
      "Evaluation at step 940000: Mean Reward = 284.99\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 197      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3420     |\n",
      "|    fps             | 128      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 940069   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 7.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 939968   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3424     |\n",
      "|    fps             | 113      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 941217   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 3.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 941116   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3428     |\n",
      "|    fps             | 113      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 942022   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99      |\n",
      "|    critic_loss     | 3.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 941921   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3432     |\n",
      "|    fps             | 112      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 942706   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 6.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 942605   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3436     |\n",
      "|    fps             | 114      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 943360   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.8    |\n",
      "|    critic_loss     | 305      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 943259   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3440     |\n",
      "|    fps             | 116      |\n",
      "|    time_elapsed    | 35       |\n",
      "|    total_timesteps | 944148   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.4    |\n",
      "|    critic_loss     | 6.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 944047   |\n",
      "---------------------------------\n",
      "Evaluation at step 945000: Mean Reward = 283.75\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 202      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3444     |\n",
      "|    fps             | 118      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 945026   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 14.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 944925   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3448     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 945855   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 8.3      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 945754   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 200      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3452     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 946663   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.7    |\n",
      "|    critic_loss     | 3.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 946562   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 199      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3456     |\n",
      "|    fps             | 127      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 947385   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -93.6    |\n",
      "|    critic_loss     | 3.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 947284   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 201      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3460     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 948398   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 5.71     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 948297   |\n",
      "---------------------------------\n",
      "Evaluation at step 950000: Mean Reward = 285.36\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3464     |\n",
      "|    fps             | 108      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 950382   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 2.92     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 950281   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 213      |\n",
      "|    ep_rew_mean     | 282      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3468     |\n",
      "|    fps             | 103      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 951309   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 45.7     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 951208   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | 283      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3472     |\n",
      "|    fps             | 107      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 953054   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 17       |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 952953   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 221      |\n",
      "|    ep_rew_mean     | 281      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3476     |\n",
      "|    fps             | 109      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 953701   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -100     |\n",
      "|    critic_loss     | 8.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 953600   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 223      |\n",
      "|    ep_rew_mean     | 280      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3480     |\n",
      "|    fps             | 111      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 954545   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 4        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 954444   |\n",
      "---------------------------------\n",
      "Evaluation at step 955000: Mean Reward = 266.83\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 231      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3484     |\n",
      "|    fps             | 118      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 956028   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 12.2     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 955927   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3488     |\n",
      "|    fps             | 119      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 957103   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 36.5     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 957002   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3492     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 957885   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 1.67     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 957784   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 236      |\n",
      "|    ep_rew_mean     | 277      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3496     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 958773   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -102     |\n",
      "|    critic_loss     | 8.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 958672   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 276      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3500     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 959526   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 2.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 959425   |\n",
      "---------------------------------\n",
      "Evaluation at step 960000: Mean Reward = 278.21\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3504     |\n",
      "|    fps             | 132      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 960236   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.4    |\n",
      "|    critic_loss     | 4.94     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 960135   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3508     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 961099   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -107     |\n",
      "|    critic_loss     | 2.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 960998   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3512     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 961846   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -95.3    |\n",
      "|    critic_loss     | 22.4     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 961745   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 235      |\n",
      "|    ep_rew_mean     | 274      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3516     |\n",
      "|    fps             | 126      |\n",
      "|    time_elapsed    | 20       |\n",
      "|    total_timesteps | 962629   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 5.38     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 962528   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 238      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3520     |\n",
      "|    fps             | 122      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 963835   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -106     |\n",
      "|    critic_loss     | 3.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 963734   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 234      |\n",
      "|    ep_rew_mean     | 275      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3524     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 964575   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.6    |\n",
      "|    critic_loss     | 3.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 964474   |\n",
      "---------------------------------\n",
      "Evaluation at step 965000: Mean Reward = 277.45\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 232      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3528     |\n",
      "|    fps             | 116      |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 965231   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -99.1    |\n",
      "|    critic_loss     | 6.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 965130   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3532     |\n",
      "|    fps             | 104      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 965957   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 965856   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3536     |\n",
      "|    fps             | 108      |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 967501   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -103     |\n",
      "|    critic_loss     | 2.75     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 967400   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 242      |\n",
      "|    ep_rew_mean     | 271      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3540     |\n",
      "|    fps             | 110      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 968317   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 5.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 968216   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 273      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3544     |\n",
      "|    fps             | 112      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 969125   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 143      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 969024   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 241      |\n",
      "|    ep_rew_mean     | 272      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3548     |\n",
      "|    fps             | 113      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 969925   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -105     |\n",
      "|    critic_loss     | 1.36     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 969824   |\n",
      "---------------------------------\n",
      "Evaluation at step 970000: Mean Reward = 274.34\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 238      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3552     |\n",
      "|    fps             | 117      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 970506   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -97.9    |\n",
      "|    critic_loss     | 7.53     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 970405   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 239      |\n",
      "|    ep_rew_mean     | 269      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3556     |\n",
      "|    fps             | 119      |\n",
      "|    time_elapsed    | 10       |\n",
      "|    total_timesteps | 971249   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -101     |\n",
      "|    critic_loss     | 403      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 971148   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 237      |\n",
      "|    ep_rew_mean     | 270      |\n",
      "| time/              |          |\n",
      "|    episodes        | 3560     |\n",
      "|    fps             | 121      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 972132   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -104     |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 972031   |\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "env = gym.make(\"LunarLander-v3\", gravity=-10, continuous=True,\n",
    "               enable_wind=False, wind_power=15.0, turbulence_power=1.5)\n",
    "env.reset(seed=seed_value)\n",
    "\n",
    "# Get dimensions\n",
    "n_actions = env.action_space.shape[0]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.2 * np.ones(n_actions))\n",
    "\n",
    "policy_kwargs = dict(net_arch=[256, 256])\n",
    "\n",
    "\n",
    "# Define model\n",
    "model = DDPG(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    action_noise=action_noise,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-3,\n",
    "    buffer_size=1_000_000,\n",
    "    batch_size=128,\n",
    "    gamma=0.99,\n",
    "    tau=0.005,\n",
    "    train_freq=(1, \"step\"),\n",
    "    gradient_steps=1,\n",
    "    device=\"auto\",  # \"cuda\" or \"cpu\"\n",
    "    seed=seed_value\n",
    ")\n",
    "\n",
    "# Track episode rewards\n",
    "episode_rewards = []\n",
    "n_eval_episodes = 10\n",
    "eval_interval = 5000  # evaluate every 5k steps\n",
    "total_timesteps = 1_000_000\n",
    "timesteps = 0\n",
    "eval_results = []\n",
    "\n",
    "# Helper function for evaluation\n",
    "def evaluate(model, env, n_episodes=10):\n",
    "    rewards = []\n",
    "    for _ in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "    return np.mean(rewards), rewards\n",
    "\n",
    "# Train in intervals, evaluate and log\n",
    "while timesteps < total_timesteps:\n",
    "    model.learn(total_timesteps=eval_interval, reset_num_timesteps=False)\n",
    "    timesteps += eval_interval\n",
    "    mean_reward, rewards = evaluate(model, env, n_episodes=n_eval_episodes)\n",
    "    episode_rewards.append(mean_reward)\n",
    "    eval_results.append({\"timesteps\": timesteps, \"mean_reward\": mean_reward})\n",
    "    print(f\"Evaluation at step {timesteps}: Mean Reward = {mean_reward:.2f}\")\n",
    "\n",
    "# Save model and close environment\n",
    "model.save(\"ddpg_lunar\")\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a899d8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Episode 1: Reward = 254.68\n",
      "Test Episode 2: Reward = 281.93\n",
      "Test Episode 3: Reward = 241.92\n",
      "Test Episode 4: Reward = -10.94\n",
      "Test Episode 5: Reward = 285.95\n",
      "Test Episode 6: Reward = -72.91\n",
      "Test Episode 7: Reward = 302.26\n",
      "Test Episode 8: Reward = 280.09\n",
      "Test Episode 9: Reward = 274.52\n",
      "Test Episode 10: Reward = 298.05\n"
     ]
    }
   ],
   "source": [
    "# Reload model and test in human mode\n",
    "from stable_baselines3 import DDPG\n",
    "import gymnasium as gym\n",
    "\n",
    "# Load environment in render mode\n",
    "test_env = gym.make(\"LunarLander-v3\", gravity=-10, continuous=True,\n",
    "               enable_wind=False, wind_power=15.0, turbulence_power=1.5, render_mode=\"human\")\n",
    "test_env.reset(seed=seed_value)\n",
    "\n",
    "# Load the model\n",
    "model = DDPG.load(\"ddpg_lunar\")\n",
    "\n",
    "# Run a few episodes\n",
    "for ep in range(10):\n",
    "    obs, _ = test_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = test_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "    print(f\"Test Episode {ep+1}: Reward = {total_reward:.2f}\")\n",
    "test_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6beb6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(eval_results)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df[\"timesteps\"], results_df[\"mean_reward\"], linewidth=2)  # thicker line\n",
    "plt.axhline(y=200, color='red', linestyle='--', linewidth=1.5)  # red dashed horizontal line at 200\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Mean Evaluation Return\")\n",
    "plt.title(\"DDPG Evaluation Performance Over Time\")\n",
    "plt.grid(True)\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1618e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_reward = results_df[\"mean_reward\"].min()\n",
    "max_reward = results_df[\"mean_reward\"].max()\n",
    "\n",
    "# Create bin edges every 25 units from min to max, adding one extra bin to cover max\n",
    "bins = np.arange(start=np.floor(min_reward / 25) * 25,\n",
    "                 stop=np.ceil(max_reward / 25) * 25 + 25,\n",
    "                 step=25)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(results_df[\"mean_reward\"], bins=bins, edgecolor='k')\n",
    "plt.xlabel(\"Mean Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Mean Evaluation Rewards (200 Evaluations)\")\n",
    "plt.grid(True, axis='x')\n",
    "plt.grid(True, axis='y', which='both')\n",
    "plt.xticks(bins, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd1679",
   "metadata": {},
   "source": [
    "# PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f09ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48061e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test/Evaluate PPO agent using your env\n",
    "env = gym.make(\"LunarLander-v3\", gravity=-10, continuous=True,\n",
    "               enable_wind=True, wind_power=15.0, turbulence_power=1.5\n",
    "    )\n",
    "env.reset(seed=seed_value)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86b7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env Properties\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "action_low = float(env.action_space.low[0])\n",
    "action_high = float(env.action_space.high[0])\n",
    "\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print('State dimension:', state_dim)\n",
    "print('Action dimension:', action_dim)\n",
    "print('Action range:', action_low, 'to', action_high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b21c9",
   "metadata": {},
   "source": [
    "The first experiment trains a PPO agent using the default hyperparameters from Stable Baselines3. Every 5,000 steps, the agent is evaluated in a fresh environment and the results are logged to monitor learning progress throughout training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e2272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./ppo_lunar_tensorboard/PPO_10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 102      |\n",
      "|    ep_rew_mean     | -359     |\n",
      "| time/              |          |\n",
      "|    fps             | 3109     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 103        |\n",
      "|    ep_rew_mean          | -352       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2149       |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 1          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00446542 |\n",
      "|    clip_fraction        | 0.0354     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.84      |\n",
      "|    explained_variance   | -0.0004    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.89e+03   |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.00509   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 4.19e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -359        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1966        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004614846 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -0.012      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 101         |\n",
      "|    ep_rew_mean          | -341        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1881        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004673356 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | -0.00596    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 3.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 102         |\n",
      "|    ep_rew_mean          | -329        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1827        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006479968 |\n",
      "|    clip_fraction        | 0.0549      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | 0.00348     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 807         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 104        |\n",
      "|    ep_rew_mean          | -320       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1775       |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00848298 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.89      |\n",
      "|    explained_variance   | -0.00116   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 597        |\n",
      "|    n_updates            | 50         |\n",
      "|    policy_gradient_loss | -0.00785   |\n",
      "|    std                  | 1.03       |\n",
      "|    value_loss           | 1.94e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 105         |\n",
      "|    ep_rew_mean          | -296        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1720        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004358507 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | -0.00801    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 707         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | -271         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1659         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053997515 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.91        |\n",
      "|    explained_variance   | -0.000284    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 467          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 955          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | -265         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1617         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 11           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048201852 |\n",
      "|    clip_fraction        | 0.0394       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.92        |\n",
      "|    explained_variance   | -0.0103      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 394          |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 1.04         |\n",
      "|    value_loss           | 997          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | -244         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077540707 |\n",
      "|    clip_fraction        | 0.0702       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.9         |\n",
      "|    explained_variance   | -0.000729    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 412          |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 110          |\n",
      "|    ep_rew_mean          | -216         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1557         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097291125 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.87        |\n",
      "|    explained_variance   | -0.000477    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 396          |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 714          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | -197         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1552         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 15           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041730665 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | -0.000313    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00694     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 349          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 109        |\n",
      "|    ep_rew_mean          | -178       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1551       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 17         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00904757 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.86      |\n",
      "|    explained_variance   | -4.57e-05  |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 205        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.00951   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 360        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 112         |\n",
      "|    ep_rew_mean          | -156        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1542        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008483739 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | -0.00249    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 115         |\n",
      "|    ep_rew_mean          | -139        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1534        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007828919 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | -0.000276   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 434         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | -130        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1528        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009659009 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.85       |\n",
      "|    explained_variance   | -8.23e-06   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 124          |\n",
      "|    ep_rew_mean          | -126         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1522         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 22           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070128567 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | 0.000439     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 132          |\n",
      "|    ep_rew_mean          | -119         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1519         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037686042 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.85        |\n",
      "|    explained_variance   | -0.00584     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 243          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 139          |\n",
      "|    ep_rew_mean          | -106         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1519         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074680196 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | -9.37e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 207          |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 322          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -97.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1517        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004218502 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.87       |\n",
      "|    explained_variance   | -0.00137    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 152          |\n",
      "|    ep_rew_mean          | -96.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1515         |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 28           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056640506 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.86        |\n",
      "|    explained_variance   | 0.00171      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.9         |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 163         |\n",
      "|    ep_rew_mean          | -89.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1514        |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004452299 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.84       |\n",
      "|    explained_variance   | 0.0282      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 176         |\n",
      "|    ep_rew_mean          | -89.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1512        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 31          |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009284067 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.83       |\n",
      "|    explained_variance   | -0.0101     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.989       |\n",
      "|    value_loss           | 396         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | -84.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1512        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007221941 |\n",
      "|    clip_fraction        | 0.058       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.81       |\n",
      "|    explained_variance   | -0.016      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 172         |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    std                  | 0.979       |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 195         |\n",
      "|    ep_rew_mean          | -78.5       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1511        |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007760913 |\n",
      "|    clip_fraction        | 0.057       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.79       |\n",
      "|    explained_variance   | -0.00443    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.973       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 214         |\n",
      "|    ep_rew_mean          | -75.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1511        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006166892 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.78       |\n",
      "|    explained_variance   | 0.0006      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 339         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 226       |\n",
      "|    ep_rew_mean          | -74.7     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1511      |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 36        |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0068258 |\n",
      "|    clip_fraction        | 0.0643    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.79     |\n",
      "|    explained_variance   | 0.00852   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 46.7      |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -0.00809  |\n",
      "|    std                  | 0.972     |\n",
      "|    value_loss           | 132       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 233        |\n",
      "|    ep_rew_mean          | -75.4      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1511       |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 37         |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00682861 |\n",
      "|    clip_fraction        | 0.0606     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.78      |\n",
      "|    explained_variance   | -0.0274    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 258        |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.00754   |\n",
      "|    std                  | 0.973      |\n",
      "|    value_loss           | 377        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | -74.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1510         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 39           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043963776 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.77        |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 124          |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 0.958        |\n",
      "|    value_loss           | 236          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | -75.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1509         |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047383932 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.75        |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 74.2         |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 186          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 279          |\n",
      "|    ep_rew_mean          | -76.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1509         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046005696 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.74        |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.952        |\n",
      "|    value_loss           | 317          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 294          |\n",
      "|    ep_rew_mean          | -75.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1509         |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066144196 |\n",
      "|    clip_fraction        | 0.0491       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.73        |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 100          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    std                  | 0.946        |\n",
      "|    value_loss           | 269          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 309         |\n",
      "|    ep_rew_mean          | -72.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1509        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006726314 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 325         |\n",
      "|    ep_rew_mean          | -73.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1509        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004736284 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.7        |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | -73.2       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1508        |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005208879 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.72       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.941       |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | -70.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1507         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075896108 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.7         |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.4         |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 82.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | -74.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1506        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007038005 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.68       |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    std                  | 0.922       |\n",
      "|    value_loss           | 59.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 378          |\n",
      "|    ep_rew_mean          | -76.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1506         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063200123 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 326          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 398          |\n",
      "|    ep_rew_mean          | -73.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1505         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054732803 |\n",
      "|    clip_fraction        | 0.0737       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 88.9         |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    std                  | 0.926        |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 418          |\n",
      "|    ep_rew_mean          | -71.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1504         |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064131375 |\n",
      "|    clip_fraction        | 0.0674       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.68        |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.7         |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 86.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | -67.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1504         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042846254 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.67        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.9         |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.916        |\n",
      "|    value_loss           | 89.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 443          |\n",
      "|    ep_rew_mean          | -63.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1504         |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064682006 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.65        |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 455          |\n",
      "|    ep_rew_mean          | -59.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1503         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 58           |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075717033 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.8         |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.906        |\n",
      "|    value_loss           | 163          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | -53.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1502         |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 59           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063945586 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.64        |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.7         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    std                  | 0.905        |\n",
      "|    value_loss           | 107          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 484        |\n",
      "|    ep_rew_mean          | -47.7      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1500       |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 61         |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00473727 |\n",
      "|    clip_fraction        | 0.0489     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.63      |\n",
      "|    explained_variance   | 0.631      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.1       |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00222   |\n",
      "|    std                  | 0.896      |\n",
      "|    value_loss           | 53.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 501          |\n",
      "|    ep_rew_mean          | -45.9        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049867644 |\n",
      "|    clip_fraction        | 0.0598       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.61        |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.3         |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.888        |\n",
      "|    value_loss           | 75           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 510         |\n",
      "|    ep_rew_mean          | -42.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1500        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005935183 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 37.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 528          |\n",
      "|    ep_rew_mean          | -41          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 65           |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037128164 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.6         |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.876        |\n",
      "|    value_loss           | 75.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 535          |\n",
      "|    ep_rew_mean          | -36          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064396937 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.8         |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    std                  | 0.877        |\n",
      "|    value_loss           | 109          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 540          |\n",
      "|    ep_rew_mean          | -35.2        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 68           |\n",
      "|    total_timesteps      | 102400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052042287 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.2         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 551          |\n",
      "|    ep_rew_mean          | -34.4        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 69           |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077500036 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.7         |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 565          |\n",
      "|    ep_rew_mean          | -35.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1500         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 70           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076350765 |\n",
      "|    clip_fraction        | 0.0754       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    std                  | 0.873        |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 566         |\n",
      "|    ep_rew_mean          | -33.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1500        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009079263 |\n",
      "|    clip_fraction        | 0.0904      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.3        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    std                  | 0.871       |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | -32.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 110592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004339613 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    std                  | 0.867       |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 581         |\n",
      "|    ep_rew_mean          | -30.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1496        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006938719 |\n",
      "|    clip_fraction        | 0.0606      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.4        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 55.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | -26.1        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060532717 |\n",
      "|    clip_fraction        | 0.0591       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.51        |\n",
      "|    explained_variance   | 0.751        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.3         |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.844        |\n",
      "|    value_loss           | 41.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 613          |\n",
      "|    ep_rew_mean          | -21.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 78           |\n",
      "|    total_timesteps      | 116736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074517597 |\n",
      "|    clip_fraction        | 0.082        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 75.1         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    std                  | 0.841        |\n",
      "|    value_loss           | 95.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 628         |\n",
      "|    ep_rew_mean          | -18.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006100053 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.77        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.837       |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 633          |\n",
      "|    ep_rew_mean          | -15.5        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 80           |\n",
      "|    total_timesteps      | 120832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039320732 |\n",
      "|    clip_fraction        | 0.0377       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.829        |\n",
      "|    value_loss           | 52.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 640          |\n",
      "|    ep_rew_mean          | -13.8        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076993504 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.47        |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25.5         |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    std                  | 0.831        |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 654         |\n",
      "|    ep_rew_mean          | -8.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005497926 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.47       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.2        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.832       |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 664         |\n",
      "|    ep_rew_mean          | -5.36       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013123492 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    std                  | 0.803       |\n",
      "|    value_loss           | 59.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 668         |\n",
      "|    ep_rew_mean          | -3.24       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007296765 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.797       |\n",
      "|    value_loss           | 22.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | 0.00941     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 87          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007812887 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    std                  | 0.795       |\n",
      "|    value_loss           | 72.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | 4.01        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008398554 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.38       |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.796       |\n",
      "|    value_loss           | 36.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 689          |\n",
      "|    ep_rew_mean          | 6.68         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 135168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078321695 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.37        |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.1         |\n",
      "|    n_updates            | 650          |\n",
      "|    policy_gradient_loss | -0.00784     |\n",
      "|    std                  | 0.789        |\n",
      "|    value_loss           | 81.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 10.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004500273 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.36       |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.787       |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 698          |\n",
      "|    ep_rew_mean          | 11.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 93           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059953853 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.15         |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | 0.000821     |\n",
      "|    std                  | 0.769        |\n",
      "|    value_loss           | 16.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 141312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007463431 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.00807    |\n",
      "|    std                  | 0.768       |\n",
      "|    value_loss           | 217         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | 14.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1494        |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005484486 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.41        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.765       |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | 17.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008128939 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 61.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 706         |\n",
      "|    ep_rew_mean          | 20.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1496        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 98          |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004831501 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.28       |\n",
      "|    explained_variance   | 0.353       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 703          |\n",
      "|    ep_rew_mean          | 20.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1496         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048873527 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.0802       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 330          |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 274          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1496        |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 151552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006111252 |\n",
      "|    clip_fraction        | 0.0613      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 0.214       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.748       |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 707         |\n",
      "|    ep_rew_mean          | 22.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004708124 |\n",
      "|    clip_fraction        | 0.0645      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.1        |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | 19.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 103         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004944603 |\n",
      "|    clip_fraction        | 0.0627      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10          |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.744       |\n",
      "|    value_loss           | 35.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 716         |\n",
      "|    ep_rew_mean          | 20          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 105         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003740315 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.7        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | 21.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006899072 |\n",
      "|    clip_fraction        | 0.0749      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    std                  | 0.74        |\n",
      "|    value_loss           | 29.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 740          |\n",
      "|    ep_rew_mean          | 22.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 161792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066388403 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.22        |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.729        |\n",
      "|    value_loss           | 77           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | 17.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008752248 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.2        |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.727       |\n",
      "|    value_loss           | 74.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 710       |\n",
      "|    ep_rew_mean          | 13.4      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1498      |\n",
      "|    iterations           | 81        |\n",
      "|    time_elapsed         | 110       |\n",
      "|    total_timesteps      | 165888    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0051271 |\n",
      "|    clip_fraction        | 0.0489    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -2.21     |\n",
      "|    explained_variance   | 0.376     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 77.5      |\n",
      "|    n_updates            | 800       |\n",
      "|    policy_gradient_loss | -0.00235  |\n",
      "|    std                  | 0.733     |\n",
      "|    value_loss           | 120       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | 17.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 112         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453562 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.152       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    std                  | 0.74        |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | 16.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010175247 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.3        |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.000935   |\n",
      "|    std                  | 0.735       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 700          |\n",
      "|    ep_rew_mean          | 17.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 172032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074944007 |\n",
      "|    clip_fraction        | 0.0816       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.23        |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 47.7         |\n",
      "|    n_updates            | 830          |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    std                  | 0.74         |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | 24.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006627335 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 716         |\n",
      "|    ep_rew_mean          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005542289 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.21       |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.724       |\n",
      "|    value_loss           | 82.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 723         |\n",
      "|    ep_rew_mean          | 28.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012464014 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.14        |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.000666   |\n",
      "|    std                  | 0.725       |\n",
      "|    value_loss           | 36.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 735        |\n",
      "|    ep_rew_mean          | 30.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1498       |\n",
      "|    iterations           | 88         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 180224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00756777 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.19      |\n",
      "|    explained_variance   | 0.407      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 870        |\n",
      "|    policy_gradient_loss | -0.00637   |\n",
      "|    std                  | 0.721      |\n",
      "|    value_loss           | 67         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 735         |\n",
      "|    ep_rew_mean          | 34.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006866995 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.16       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 742         |\n",
      "|    ep_rew_mean          | 33.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009262324 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.703       |\n",
      "|    value_loss           | 53          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 726          |\n",
      "|    ep_rew_mean          | 35.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 186368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055588093 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 137          |\n",
      "|    n_updates            | 900          |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.706        |\n",
      "|    value_loss           | 153          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | 33.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008538917 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.13       |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.7         |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 707          |\n",
      "|    ep_rew_mean          | 38           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 93           |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 190464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076883286 |\n",
      "|    clip_fraction        | 0.0835       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.279        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 920          |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    std                  | 0.7          |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 35.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009059886 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 80.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | 34          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004776777 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    std                  | 0.697       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | 34.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058591375 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.11        |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    std                  | 0.695        |\n",
      "|    value_loss           | 70.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | 37.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764082 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.663       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.7        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 51.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 676         |\n",
      "|    ep_rew_mean          | 36.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 200704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006995042 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.685       |\n",
      "|    value_loss           | 49.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 675         |\n",
      "|    ep_rew_mean          | 38.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004764895 |\n",
      "|    clip_fraction        | 0.036       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.3        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    std                  | 0.691       |\n",
      "|    value_loss           | 89.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 665          |\n",
      "|    ep_rew_mean          | 40.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054491647 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.1         |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 114          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 660          |\n",
      "|    ep_rew_mean          | 42.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 206848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066180797 |\n",
      "|    clip_fraction        | 0.0789       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.622        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 1000         |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 654          |\n",
      "|    ep_rew_mean          | 46           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 139          |\n",
      "|    total_timesteps      | 208896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037579238 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.6         |\n",
      "|    n_updates            | 1010         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 653         |\n",
      "|    ep_rew_mean          | 49          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 103         |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 210944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008043216 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.294       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    std                  | 0.685       |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 652        |\n",
      "|    ep_rew_mean          | 51.1       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1498       |\n",
      "|    iterations           | 104        |\n",
      "|    time_elapsed         | 142        |\n",
      "|    total_timesteps      | 212992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00956222 |\n",
      "|    clip_fraction        | 0.0952     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.08      |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 66.1       |\n",
      "|    n_updates            | 1030       |\n",
      "|    policy_gradient_loss | -0.00524   |\n",
      "|    std                  | 0.684      |\n",
      "|    value_loss           | 149        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 667         |\n",
      "|    ep_rew_mean          | 55.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 143         |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012184655 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.6         |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | 5.82e-05    |\n",
      "|    std                  | 0.676       |\n",
      "|    value_loss           | 39.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 664         |\n",
      "|    ep_rew_mean          | 60.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 144         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007480885 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48        |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    std                  | 0.666       |\n",
      "|    value_loss           | 11.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 661          |\n",
      "|    ep_rew_mean          | 57.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 146          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091306055 |\n",
      "|    clip_fraction        | 0.0871       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.5         |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.663        |\n",
      "|    value_loss           | 77.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 660          |\n",
      "|    ep_rew_mean          | 59.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 108          |\n",
      "|    time_elapsed         | 147          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057736533 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.16         |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    std                  | 0.664        |\n",
      "|    value_loss           | 50.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 666         |\n",
      "|    ep_rew_mean          | 62.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 148         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007971773 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    std                  | 0.656       |\n",
      "|    value_loss           | 50.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 656          |\n",
      "|    ep_rew_mean          | 66.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 225280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070419647 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 1090         |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    std                  | 0.641        |\n",
      "|    value_loss           | 30.1         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 652        |\n",
      "|    ep_rew_mean          | 68.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1499       |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 151        |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00706272 |\n",
      "|    clip_fraction        | 0.0855     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | 0.459      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    std                  | 0.633      |\n",
      "|    value_loss           | 87.9       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 651          |\n",
      "|    ep_rew_mean          | 69.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074807946 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 72.1         |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    std                  | 0.625        |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | 73          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 231424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008199543 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.629       |\n",
      "|    value_loss           | 98.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 662         |\n",
      "|    ep_rew_mean          | 69.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813489 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.9        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.97        |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    std                  | 0.621       |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 659          |\n",
      "|    ep_rew_mean          | 67.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 235520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056204726 |\n",
      "|    clip_fraction        | 0.0542       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.89        |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14.8         |\n",
      "|    n_updates            | 1140         |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.628        |\n",
      "|    value_loss           | 78.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 675          |\n",
      "|    ep_rew_mean          | 71.9         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 158          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051323427 |\n",
      "|    clip_fraction        | 0.0757       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.64         |\n",
      "|    n_updates            | 1150         |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    std                  | 0.628        |\n",
      "|    value_loss           | 52.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | 73.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 159         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005110407 |\n",
      "|    clip_fraction        | 0.0439      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36        |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.63        |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 688          |\n",
      "|    ep_rew_mean          | 70.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 161          |\n",
      "|    total_timesteps      | 241664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110642435 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.03         |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.629        |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 671          |\n",
      "|    ep_rew_mean          | 70.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 162          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064519197 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.605        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.1         |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 0.622        |\n",
      "|    value_loss           | 85           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 671         |\n",
      "|    ep_rew_mean          | 71          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 163         |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005979256 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.621       |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 671         |\n",
      "|    ep_rew_mean          | 72.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007473533 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.000477   |\n",
      "|    std                  | 0.619       |\n",
      "|    value_loss           | 34          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 667          |\n",
      "|    ep_rew_mean          | 74.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 166          |\n",
      "|    total_timesteps      | 249856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077043427 |\n",
      "|    clip_fraction        | 0.0812       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 1210         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.616        |\n",
      "|    value_loss           | 88.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | 70.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 123          |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 251904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053182403 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.585        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.4         |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.615        |\n",
      "|    value_loss           | 152          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | 72.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1499        |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 169         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010108145 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.556       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.613       |\n",
      "|    value_loss           | 97.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | 74.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 256000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077688214 |\n",
      "|    clip_fraction        | 0.0827       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.4         |\n",
      "|    n_updates            | 1240         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    std                  | 0.617        |\n",
      "|    value_loss           | 77.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 659          |\n",
      "|    ep_rew_mean          | 69.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1499         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 172          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055525955 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.87        |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.1         |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    std                  | 0.614        |\n",
      "|    value_loss           | 55           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 673          |\n",
      "|    ep_rew_mean          | 73           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 127          |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 260096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028096368 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.762        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.8         |\n",
      "|    n_updates            | 1260         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.614        |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 674         |\n",
      "|    ep_rew_mean          | 75.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008921033 |\n",
      "|    clip_fraction        | 0.0853      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.86       |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.87        |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.615       |\n",
      "|    value_loss           | 27.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 674         |\n",
      "|    ep_rew_mean          | 73.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 176         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027561 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.68        |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.606       |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 674         |\n",
      "|    ep_rew_mean          | 73.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004753665 |\n",
      "|    clip_fraction        | 0.0642      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    std                  | 0.599       |\n",
      "|    value_loss           | 43.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 672         |\n",
      "|    ep_rew_mean          | 74.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007587284 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.000996   |\n",
      "|    std                  | 0.597       |\n",
      "|    value_loss           | 48.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 675          |\n",
      "|    ep_rew_mean          | 74.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 132          |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 270336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072794165 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.8         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 87.5         |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    std                  | 0.594        |\n",
      "|    value_loss           | 128          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 681          |\n",
      "|    ep_rew_mean          | 72.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 181          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045700697 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | 0.616        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55.1         |\n",
      "|    n_updates            | 1320         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    std                  | 0.583        |\n",
      "|    value_loss           | 58.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 73          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008167491 |\n",
      "|    clip_fraction        | 0.0572      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.5         |\n",
      "|    n_updates            | 1330        |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.582       |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | 74.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 184         |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011461213 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.1         |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    std                  | 0.581       |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 710          |\n",
      "|    ep_rew_mean          | 74.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129822865 |\n",
      "|    clip_fraction        | 0.0967       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.39         |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    std                  | 0.576        |\n",
      "|    value_loss           | 18.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | 73.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 137         |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 280576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005842552 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.4        |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    std                  | 0.57        |\n",
      "|    value_loss           | 86.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 729         |\n",
      "|    ep_rew_mean          | 73.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 188         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010155672 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    std                  | 0.564       |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 734         |\n",
      "|    ep_rew_mean          | 71          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1498        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007163058 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37        |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.000528   |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 10.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 729          |\n",
      "|    ep_rew_mean          | 68.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1498         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041477415 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52           |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 0.564        |\n",
      "|    value_loss           | 150          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | 64.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 192         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006771352 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.563       |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 735         |\n",
      "|    ep_rew_mean          | 62.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 142         |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 290816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008121972 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    std                  | 0.558       |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 734          |\n",
      "|    ep_rew_mean          | 64.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 143          |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 292864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118304435 |\n",
      "|    clip_fraction        | 0.095        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.9         |\n",
      "|    n_updates            | 1420         |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    std                  | 0.546        |\n",
      "|    value_loss           | 25.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 740         |\n",
      "|    ep_rew_mean          | 64.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1497        |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014108401 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.4        |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 94.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 726          |\n",
      "|    ep_rew_mean          | 60.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1497         |\n",
      "|    iterations           | 145          |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 296960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049266065 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 25.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 710          |\n",
      "|    ep_rew_mean          | 54.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1496         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067311777 |\n",
      "|    clip_fraction        | 0.059        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | 57.7         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 147          |\n",
      "|    time_elapsed         | 201          |\n",
      "|    total_timesteps      | 301056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065153735 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.59        |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.9         |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.539        |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 715        |\n",
      "|    ep_rew_mean          | 57.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 202        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02011222 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.58      |\n",
      "|    explained_variance   | 0.729      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39         |\n",
      "|    n_updates            | 1470       |\n",
      "|    policy_gradient_loss | 0.000425   |\n",
      "|    std                  | 0.535      |\n",
      "|    value_loss           | 65.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 61.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 204         |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007341369 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.02        |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    std                  | 0.536       |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 59.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 205         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005477162 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.000143   |\n",
      "|    std                  | 0.528       |\n",
      "|    value_loss           | 66.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | 61          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 206         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008526228 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07        |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 9.41        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 704         |\n",
      "|    ep_rew_mean          | 59.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 152         |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007050516 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.09        |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    std                  | 0.507       |\n",
      "|    value_loss           | 99.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 707          |\n",
      "|    ep_rew_mean          | 58           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 313344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056038364 |\n",
      "|    clip_fraction        | 0.0587       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.47        |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.3         |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    std                  | 0.507        |\n",
      "|    value_loss           | 69.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 59.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 210         |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006606253 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    std                  | 0.508       |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 57.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 212         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011731584 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.12        |\n",
      "|    n_updates            | 1540        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 700        |\n",
      "|    ep_rew_mean          | 57.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 156        |\n",
      "|    time_elapsed         | 213        |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00679556 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.43      |\n",
      "|    explained_variance   | 0.606      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12         |\n",
      "|    n_updates            | 1550       |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    std                  | 0.497      |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 711          |\n",
      "|    ep_rew_mean          | 57.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 321536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105548855 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4            |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 16.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 716         |\n",
      "|    ep_rew_mean          | 58.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010689214 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.63        |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    std                  | 0.489       |\n",
      "|    value_loss           | 15.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 717         |\n",
      "|    ep_rew_mean          | 59.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 159         |\n",
      "|    time_elapsed         | 217         |\n",
      "|    total_timesteps      | 325632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011936386 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 0.492       |\n",
      "|    value_loss           | 79.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 710        |\n",
      "|    ep_rew_mean          | 61.4       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 160        |\n",
      "|    time_elapsed         | 219        |\n",
      "|    total_timesteps      | 327680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00643792 |\n",
      "|    clip_fraction        | 0.0932     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55.4       |\n",
      "|    n_updates            | 1590       |\n",
      "|    policy_gradient_loss | -0.00695   |\n",
      "|    std                  | 0.488      |\n",
      "|    value_loss           | 77         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 711          |\n",
      "|    ep_rew_mean          | 64.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 220          |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064429166 |\n",
      "|    clip_fraction        | 0.0767       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.7         |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 89.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 704         |\n",
      "|    ep_rew_mean          | 62.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 162         |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 331776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005781519 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.6        |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    std                  | 0.487       |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 703         |\n",
      "|    ep_rew_mean          | 62.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 223         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006981854 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.47        |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 708          |\n",
      "|    ep_rew_mean          | 64.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 224          |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068254857 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.672        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.51         |\n",
      "|    n_updates            | 1630         |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 0.492        |\n",
      "|    value_loss           | 49.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 63.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015198819 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.921       |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | 0.000275    |\n",
      "|    std                  | 0.486       |\n",
      "|    value_loss           | 10          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 717         |\n",
      "|    ep_rew_mean          | 61.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 227         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006183076 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.4         |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.000525   |\n",
      "|    std                  | 0.483       |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 725         |\n",
      "|    ep_rew_mean          | 65.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 167         |\n",
      "|    time_elapsed         | 228         |\n",
      "|    total_timesteps      | 342016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008230964 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.000681   |\n",
      "|    std                  | 0.479       |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 717        |\n",
      "|    ep_rew_mean          | 67.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 168        |\n",
      "|    time_elapsed         | 230        |\n",
      "|    total_timesteps      | 344064     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00712318 |\n",
      "|    clip_fraction        | 0.0741     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.737      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.87       |\n",
      "|    n_updates            | 1670       |\n",
      "|    policy_gradient_loss | -0.000329  |\n",
      "|    std                  | 0.478      |\n",
      "|    value_loss           | 52.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | 69.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007802844 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    std                  | 0.473       |\n",
      "|    value_loss           | 63.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 701         |\n",
      "|    ep_rew_mean          | 73.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007750743 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 47.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 695          |\n",
      "|    ep_rew_mean          | 72.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 234          |\n",
      "|    total_timesteps      | 350208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088269515 |\n",
      "|    clip_fraction        | 0.0854       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.2         |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 0.467        |\n",
      "|    value_loss           | 115          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | 72.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 235         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005668765 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    std                  | 0.469       |\n",
      "|    value_loss           | 55.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 699          |\n",
      "|    ep_rew_mean          | 78           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1495         |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128937755 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69         |\n",
      "|    n_updates            | 1720         |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 7.77         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 696         |\n",
      "|    ep_rew_mean          | 84.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1495        |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 238         |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009825755 |\n",
      "|    clip_fraction        | 0.0912      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.38        |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 0.461       |\n",
      "|    value_loss           | 32.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 689        |\n",
      "|    ep_rew_mean          | 90.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1495       |\n",
      "|    iterations           | 175        |\n",
      "|    time_elapsed         | 239        |\n",
      "|    total_timesteps      | 358400     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553972 |\n",
      "|    clip_fraction        | 0.0571     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.591      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.9       |\n",
      "|    n_updates            | 1740       |\n",
      "|    policy_gradient_loss | -0.00235   |\n",
      "|    std                  | 0.458      |\n",
      "|    value_loss           | 97         |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 683          |\n",
      "|    ep_rew_mean          | 91           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1494         |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 241          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065851095 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.9         |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.457        |\n",
      "|    value_loss           | 92.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 682         |\n",
      "|    ep_rew_mean          | 91.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 242         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008081402 |\n",
      "|    clip_fraction        | 0.0631      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.87        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.000465   |\n",
      "|    std                  | 0.457       |\n",
      "|    value_loss           | 41.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | 96.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 244         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007983648 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.459       |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 684          |\n",
      "|    ep_rew_mean          | 98.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 245          |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072686537 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 0.456        |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 246         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008176679 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 682         |\n",
      "|    ep_rew_mean          | 99          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 181         |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 370688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014039492 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 1800        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    std                  | 0.451       |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 689         |\n",
      "|    ep_rew_mean          | 101         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 249         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009771039 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.55        |\n",
      "|    n_updates            | 1810        |\n",
      "|    policy_gradient_loss | -0.00082    |\n",
      "|    std                  | 0.454       |\n",
      "|    value_loss           | 86          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 694         |\n",
      "|    ep_rew_mean          | 103         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 251         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009558795 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.604       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    std                  | 0.458       |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 687        |\n",
      "|    ep_rew_mean          | 105        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1492       |\n",
      "|    iterations           | 184        |\n",
      "|    time_elapsed         | 252        |\n",
      "|    total_timesteps      | 376832     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00858368 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.647      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 1830       |\n",
      "|    policy_gradient_loss | -0.000916  |\n",
      "|    std                  | 0.448      |\n",
      "|    value_loss           | 45.4       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 689          |\n",
      "|    ep_rew_mean          | 112          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 253          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080396095 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 54.9         |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 0.447        |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 685         |\n",
      "|    ep_rew_mean          | 114         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 186         |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 380928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005261873 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -1.76e-05   |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 674          |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071643996 |\n",
      "|    clip_fraction        | 0.0586       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.5         |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    std                  | 0.438        |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 681          |\n",
      "|    ep_rew_mean          | 124          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 257          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060694925 |\n",
      "|    clip_fraction        | 0.0604       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.04         |\n",
      "|    n_updates            | 1870         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.431        |\n",
      "|    value_loss           | 57.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | 124         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 259         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008471084 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.428       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 660         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009346024 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    std                  | 0.424       |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | 123         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 191         |\n",
      "|    time_elapsed         | 262         |\n",
      "|    total_timesteps      | 391168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008796394 |\n",
      "|    clip_fraction        | 0.0824      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.6        |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.423       |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | 128         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009091821 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.000792   |\n",
      "|    std                  | 0.414       |\n",
      "|    value_loss           | 27          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 659         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 264         |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006284699 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.412       |\n",
      "|    value_loss           | 98.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 652          |\n",
      "|    ep_rew_mean          | 131          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 397312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062342547 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.1         |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 0.412        |\n",
      "|    value_loss           | 191          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 644         |\n",
      "|    ep_rew_mean          | 134         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 267         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008276802 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    std                  | 0.407       |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 638         |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 196         |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007131496 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.632       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 640          |\n",
      "|    ep_rew_mean          | 140          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 270          |\n",
      "|    total_timesteps      | 403456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074050836 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.978       |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.9         |\n",
      "|    n_updates            | 1960         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 113          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 634         |\n",
      "|    ep_rew_mean          | 137         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 271         |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008958897 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.976      |\n",
      "|    explained_variance   | 0.735       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.92        |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.000805   |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 625          |\n",
      "|    ep_rew_mean          | 137          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 272          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068793576 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.957       |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 55.4         |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.00023     |\n",
      "|    std                  | 0.393        |\n",
      "|    value_loss           | 98.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 625          |\n",
      "|    ep_rew_mean          | 136          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 274          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106674405 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.393        |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 629         |\n",
      "|    ep_rew_mean          | 135         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 201         |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 411648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006623602 |\n",
      "|    clip_fraction        | 0.0761      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.941      |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -9.89e-05   |\n",
      "|    std                  | 0.391       |\n",
      "|    value_loss           | 40.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 618         |\n",
      "|    ep_rew_mean          | 139         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 277         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015143459 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | 0.000108    |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 91.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 614         |\n",
      "|    ep_rew_mean          | 137         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 278         |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007763852 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    std                  | 0.385       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 616         |\n",
      "|    ep_rew_mean          | 138         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 279         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009965731 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 2030        |\n",
      "|    policy_gradient_loss | 0.000744    |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | 136          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 281          |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054513398 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.895       |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.2         |\n",
      "|    n_updates            | 2040         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 0.382        |\n",
      "|    value_loss           | 87.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 608          |\n",
      "|    ep_rew_mean          | 138          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 206          |\n",
      "|    time_elapsed         | 282          |\n",
      "|    total_timesteps      | 421888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054590516 |\n",
      "|    clip_fraction        | 0.0806       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0.682        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 2050         |\n",
      "|    policy_gradient_loss | 0.00122      |\n",
      "|    std                  | 0.378        |\n",
      "|    value_loss           | 69.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 603          |\n",
      "|    ep_rew_mean          | 140          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 283          |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076576774 |\n",
      "|    clip_fraction        | 0.0908       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.854       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | 0.000925     |\n",
      "|    std                  | 0.376        |\n",
      "|    value_loss           | 49.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 604         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 285         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010021057 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.836      |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.372       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 607         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 209         |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 428032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008162588 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 2080        |\n",
      "|    policy_gradient_loss | -0.000231   |\n",
      "|    std                  | 0.369       |\n",
      "|    value_loss           | 71.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 605         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 210         |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 430080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007069744 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.2         |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | 0.00184     |\n",
      "|    std                  | 0.368       |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 598         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013086205 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.793      |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.9        |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | 0.00307     |\n",
      "|    std                  | 0.365       |\n",
      "|    value_loss           | 51.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 590         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 290         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010515079 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | 0.000719    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 71          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 582        |\n",
      "|    ep_rew_mean          | 148        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1493       |\n",
      "|    iterations           | 213        |\n",
      "|    time_elapsed         | 292        |\n",
      "|    total_timesteps      | 436224     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847101 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | 0.677      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.1       |\n",
      "|    n_updates            | 2120       |\n",
      "|    policy_gradient_loss | 0.00184    |\n",
      "|    std                  | 0.364      |\n",
      "|    value_loss           | 86.2       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 569          |\n",
      "|    ep_rew_mean          | 142          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069002896 |\n",
      "|    clip_fraction        | 0.0821       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.763       |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.000248    |\n",
      "|    std                  | 0.36         |\n",
      "|    value_loss           | 96.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 571          |\n",
      "|    ep_rew_mean          | 142          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 215          |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 440320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061076283 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.751       |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.3         |\n",
      "|    n_updates            | 2140         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 231          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 296         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009398587 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.731      |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.8        |\n",
      "|    n_updates            | 2150        |\n",
      "|    policy_gradient_loss | -0.000982   |\n",
      "|    std                  | 0.353       |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 573         |\n",
      "|    ep_rew_mean          | 140         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 297         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010878449 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | 0.000985    |\n",
      "|    std                  | 0.35        |\n",
      "|    value_loss           | 34.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 564         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 298         |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009117258 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.691      |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.35        |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 561         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013406559 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.673      |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    std                  | 0.344       |\n",
      "|    value_loss           | 47.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 220         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008144105 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.665      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | 0.000903    |\n",
      "|    std                  | 0.346       |\n",
      "|    value_loss           | 52.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 563         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 303         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007007895 |\n",
      "|    clip_fraction        | 0.0916      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | 0.000388    |\n",
      "|    std                  | 0.346       |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 569          |\n",
      "|    ep_rew_mean          | 150          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 304          |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095664095 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.664       |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.6         |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.347        |\n",
      "|    value_loss           | 94.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 565          |\n",
      "|    ep_rew_mean          | 153          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 305          |\n",
      "|    total_timesteps      | 456704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074579967 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.675       |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.1         |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    std                  | 0.347        |\n",
      "|    value_loss           | 24.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 553         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 307         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007111338 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.7        |\n",
      "|    n_updates            | 2230        |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.344       |\n",
      "|    value_loss           | 74.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 225         |\n",
      "|    time_elapsed         | 308         |\n",
      "|    total_timesteps      | 460800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010392598 |\n",
      "|    clip_fraction        | 0.0924      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.641      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.339       |\n",
      "|    value_loss           | 56.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 540        |\n",
      "|    ep_rew_mean          | 156        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1493       |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 309        |\n",
      "|    total_timesteps      | 462848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185419 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.633     |\n",
      "|    explained_variance   | 0.703      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.6       |\n",
      "|    n_updates            | 2250       |\n",
      "|    policy_gradient_loss | -0.00403   |\n",
      "|    std                  | 0.342      |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 311         |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015588943 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    std                  | 0.345       |\n",
      "|    value_loss           | 89.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 541         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 312         |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006022839 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 26.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 533         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 314         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010687153 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.38        |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.000577   |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 527         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 230         |\n",
      "|    time_elapsed         | 315         |\n",
      "|    total_timesteps      | 471040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011444478 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.345       |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 520          |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 473088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036673797 |\n",
      "|    clip_fraction        | 0.0603       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.646       |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 2300         |\n",
      "|    policy_gradient_loss | -0.00024     |\n",
      "|    std                  | 0.343        |\n",
      "|    value_loss           | 106          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 510          |\n",
      "|    ep_rew_mean          | 155          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1493         |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 318          |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043621534 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.64        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 215          |\n",
      "|    n_updates            | 2310         |\n",
      "|    policy_gradient_loss | -5.8e-05     |\n",
      "|    std                  | 0.344        |\n",
      "|    value_loss           | 290          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 319         |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013083629 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    std                  | 0.34        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 502         |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 320         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007156579 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.639      |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | 0.0017      |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 63.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 507         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 235         |\n",
      "|    time_elapsed         | 322         |\n",
      "|    total_timesteps      | 481280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008560459 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.651      |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 2340        |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.345       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1493        |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009228414 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.646      |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | 0.00381     |\n",
      "|    std                  | 0.346       |\n",
      "|    value_loss           | 66.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 506         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 325         |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010316013 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.643      |\n",
      "|    explained_variance   | 0.494       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.344       |\n",
      "|    value_loss           | 66.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 504         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006171884 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.000246   |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 76.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 498         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009632576 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 2380        |\n",
      "|    policy_gradient_loss | -2.32e-05   |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 495         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 240         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 491520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008046143 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 2390        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    std                  | 0.343       |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 493         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014745541 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | 0.00474     |\n",
      "|    std                  | 0.343       |\n",
      "|    value_loss           | 52.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 487        |\n",
      "|    ep_rew_mean          | 177        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1492       |\n",
      "|    iterations           | 242        |\n",
      "|    time_elapsed         | 332        |\n",
      "|    total_timesteps      | 495616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01209938 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.617     |\n",
      "|    explained_variance   | 0.753      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 2410       |\n",
      "|    policy_gradient_loss | -0.00186   |\n",
      "|    std                  | 0.34       |\n",
      "|    value_loss           | 51.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 471        |\n",
      "|    ep_rew_mean          | 178        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1492       |\n",
      "|    iterations           | 243        |\n",
      "|    time_elapsed         | 333        |\n",
      "|    total_timesteps      | 497664     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892894 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.611     |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 48.5       |\n",
      "|    n_updates            | 2420       |\n",
      "|    policy_gradient_loss | -0.00292   |\n",
      "|    std                  | 0.34       |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 471         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 334         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009358839 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -2.72e-05   |\n",
      "|    std                  | 0.338       |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 460         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 245         |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 501760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009493517 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.597      |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.000625   |\n",
      "|    std                  | 0.338       |\n",
      "|    value_loss           | 95.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 456          |\n",
      "|    ep_rew_mean          | 174          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 246          |\n",
      "|    time_elapsed         | 337          |\n",
      "|    total_timesteps      | 503808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076880706 |\n",
      "|    clip_fraction        | 0.0926       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 2450         |\n",
      "|    policy_gradient_loss | 0.000103     |\n",
      "|    std                  | 0.334        |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 448          |\n",
      "|    ep_rew_mean          | 173          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 505856       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077564055 |\n",
      "|    clip_fraction        | 0.0955       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.1         |\n",
      "|    n_updates            | 2460         |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    std                  | 0.332        |\n",
      "|    value_loss           | 172          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 248         |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007025984 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.52        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.6        |\n",
      "|    n_updates            | 2470        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.331       |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | 172          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099297725 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 347          |\n",
      "|    n_updates            | 2480         |\n",
      "|    policy_gradient_loss | -0.00814     |\n",
      "|    std                  | 0.332        |\n",
      "|    value_loss           | 403          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 435         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 250         |\n",
      "|    time_elapsed         | 342         |\n",
      "|    total_timesteps      | 512000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012604728 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | 0.0025      |\n",
      "|    std                  | 0.329       |\n",
      "|    value_loss           | 47.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 427         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016430404 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.1        |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | 0.00397     |\n",
      "|    std                  | 0.325       |\n",
      "|    value_loss           | 26.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 433          |\n",
      "|    ep_rew_mean          | 176          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 345          |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070121493 |\n",
      "|    clip_fraction        | 0.0909       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.732        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.5         |\n",
      "|    n_updates            | 2510         |\n",
      "|    policy_gradient_loss | 0.00114      |\n",
      "|    std                  | 0.327        |\n",
      "|    value_loss           | 95.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 431         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 347         |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007272198 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.536      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | 0.00236     |\n",
      "|    std                  | 0.328       |\n",
      "|    value_loss           | 33.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | 178          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 254          |\n",
      "|    time_elapsed         | 348          |\n",
      "|    total_timesteps      | 520192       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069263065 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.325        |\n",
      "|    value_loss           | 137          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 428         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 349         |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018185921 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.1         |\n",
      "|    n_updates            | 2540        |\n",
      "|    policy_gradient_loss | 0.00284     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010208549 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.7        |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.000737   |\n",
      "|    std                  | 0.324       |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005608598 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 413         |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 354         |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011478686 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.6        |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.000438   |\n",
      "|    std                  | 0.325       |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 417         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 259         |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 530432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010571243 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.8        |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 168         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 415          |\n",
      "|    ep_rew_mean          | 165          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135489255 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.34         |\n",
      "|    n_updates            | 2590         |\n",
      "|    policy_gradient_loss | 0.00188      |\n",
      "|    std                  | 0.322        |\n",
      "|    value_loss           | 71.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 415         |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308802 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 359         |\n",
      "|    total_timesteps      | 536576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010018351 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77        |\n",
      "|    n_updates            | 2610        |\n",
      "|    policy_gradient_loss | -0.000826   |\n",
      "|    std                  | 0.319       |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 360         |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011340277 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.6        |\n",
      "|    n_updates            | 2620        |\n",
      "|    policy_gradient_loss | 0.000459    |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 426          |\n",
      "|    ep_rew_mean          | 150          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 264          |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053481134 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.5         |\n",
      "|    n_updates            | 2630         |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.322        |\n",
      "|    value_loss           | 159          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 363         |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449518 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | 0.00042     |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 93.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 450         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023923818 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 60.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 445       |\n",
      "|    ep_rew_mean          | 146       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1492      |\n",
      "|    iterations           | 267       |\n",
      "|    time_elapsed         | 366       |\n",
      "|    total_timesteps      | 546816    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0167777 |\n",
      "|    clip_fraction        | 0.189     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.485    |\n",
      "|    explained_variance   | 0.434     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.54      |\n",
      "|    n_updates            | 2660      |\n",
      "|    policy_gradient_loss | 0.0068    |\n",
      "|    std                  | 0.32      |\n",
      "|    value_loss           | 14.4      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 447         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 367         |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007495352 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 2670        |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 446         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 269         |\n",
      "|    time_elapsed         | 369         |\n",
      "|    total_timesteps      | 550912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006975783 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.4        |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | 0.000452    |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 78.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 441          |\n",
      "|    ep_rew_mean          | 154          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072890683 |\n",
      "|    clip_fraction        | 0.0578       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.665        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.3         |\n",
      "|    n_updates            | 2690         |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.32         |\n",
      "|    value_loss           | 171          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 446          |\n",
      "|    ep_rew_mean          | 152          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 555008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054626474 |\n",
      "|    clip_fraction        | 0.0783       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 49.8         |\n",
      "|    n_updates            | 2700         |\n",
      "|    policy_gradient_loss | 0.000255     |\n",
      "|    std                  | 0.318        |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 441         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 373         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009309554 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    std                  | 0.317       |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 441         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 374         |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007817683 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.4        |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 99.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | 153          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 274          |\n",
      "|    time_elapsed         | 376          |\n",
      "|    total_timesteps      | 561152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071804863 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 62.6         |\n",
      "|    n_updates            | 2730         |\n",
      "|    policy_gradient_loss | 0.00265      |\n",
      "|    std                  | 0.319        |\n",
      "|    value_loss           | 124          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | 154          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074350545 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.000731    |\n",
      "|    std                  | 0.315        |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 434         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 378         |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008016173 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.313       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 428         |\n",
      "|    ep_rew_mean          | 156         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 380         |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008063976 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.426      |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.62        |\n",
      "|    n_updates            | 2760        |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 80.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 427         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 381         |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007348871 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.647       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.000622   |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 279         |\n",
      "|    time_elapsed         | 382         |\n",
      "|    total_timesteps      | 571392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009774114 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.6        |\n",
      "|    n_updates            | 2780        |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 255         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 429        |\n",
      "|    ep_rew_mean          | 150        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1492       |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 384        |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01315854 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.411     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.4       |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.00448   |\n",
      "|    std                  | 0.314      |\n",
      "|    value_loss           | 157        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 443        |\n",
      "|    ep_rew_mean          | 148        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1492       |\n",
      "|    iterations           | 281        |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 575488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01150984 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.411     |\n",
      "|    explained_variance   | 0.722      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.79       |\n",
      "|    n_updates            | 2800       |\n",
      "|    policy_gradient_loss | 0.00325    |\n",
      "|    std                  | 0.313      |\n",
      "|    value_loss           | 27.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013051704 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18        |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 27.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 425          |\n",
      "|    ep_rew_mean          | 145          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 388          |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069897175 |\n",
      "|    clip_fraction        | 0.0973       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.805        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 37.8         |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | -0.000888    |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 101          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 284         |\n",
      "|    time_elapsed         | 389         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009395704 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    std                  | 0.313       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 391         |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005360312 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 2840        |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.313       |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 392         |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006941506 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.411      |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.000948   |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 409         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 393         |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642888 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25        |\n",
      "|    n_updates            | 2860        |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 39.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 408         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016128585 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.000816   |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 289         |\n",
      "|    time_elapsed         | 396         |\n",
      "|    total_timesteps      | 591872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014285687 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 2880        |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 87.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 414         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 397         |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010929046 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.9        |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | 0.000332    |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 41.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 418          |\n",
      "|    ep_rew_mean          | 153          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 399          |\n",
      "|    total_timesteps      | 595968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111744115 |\n",
      "|    clip_fraction        | 0.0967       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26.9         |\n",
      "|    n_updates            | 2900         |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    std                  | 0.31         |\n",
      "|    value_loss           | 226          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 400         |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008518094 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.000445   |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 61.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 427         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 293         |\n",
      "|    time_elapsed         | 402         |\n",
      "|    total_timesteps      | 600064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012988562 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | 0.00377     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 82.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 428         |\n",
      "|    ep_rew_mean          | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 403         |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012369754 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.404      |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.57        |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | 0.00265     |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 36.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012295466 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.9        |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | 0.00384     |\n",
      "|    std                  | 0.307       |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 433         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 296         |\n",
      "|    time_elapsed         | 406         |\n",
      "|    total_timesteps      | 606208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007556709 |\n",
      "|    clip_fraction        | 0.0773      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 306         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 436         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 407         |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011516233 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 2960        |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    std                  | 0.303       |\n",
      "|    value_loss           | 50.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 437         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 298         |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 610304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010320413 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.351      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7         |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | 0.00313     |\n",
      "|    std                  | 0.297       |\n",
      "|    value_loss           | 22.3        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 431          |\n",
      "|    ep_rew_mean          | 152          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064340075 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.329       |\n",
      "|    explained_variance   | 0.685        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.1         |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.296        |\n",
      "|    value_loss           | 142          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 411         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010604415 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.32       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | 0.000638    |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 58.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 413         |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009821351 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    std                  | 0.294       |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 414         |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012202154 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.8         |\n",
      "|    n_updates            | 3010        |\n",
      "|    policy_gradient_loss | 0.00647     |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 14.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 303         |\n",
      "|    time_elapsed         | 415         |\n",
      "|    total_timesteps      | 620544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003436492 |\n",
      "|    clip_fraction        | 0.0503      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.265      |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.8        |\n",
      "|    n_updates            | 3020        |\n",
      "|    policy_gradient_loss | -4.01e-05   |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 414         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010187707 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.27       |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 416         |\n",
      "|    ep_rew_mean          | 144         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 418         |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007374373 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.277      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | 142         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 626688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014465017 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.278      |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 3050        |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 99.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008610292 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | -0.000695   |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | 139         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 308         |\n",
      "|    time_elapsed         | 422         |\n",
      "|    total_timesteps      | 630784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012860217 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.261      |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.286       |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 414         |\n",
      "|    ep_rew_mean          | 137         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1492        |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 424         |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008839784 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.000924   |\n",
      "|    std                  | 0.287       |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 425         |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012197735 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.241      |\n",
      "|    explained_variance   | 0.531       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    std                  | 0.284       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 416         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 427         |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012855174 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.207      |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.4        |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | 0.0041      |\n",
      "|    std                  | 0.279       |\n",
      "|    value_loss           | 61          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014168512 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.174      |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 3110        |\n",
      "|    policy_gradient_loss | 0.00215     |\n",
      "|    std                  | 0.275       |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 405         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 313         |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 641024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009774113 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 3120        |\n",
      "|    policy_gradient_loss | -0.000277   |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 396         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007682058 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.148      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | 0.00202     |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 93.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 388         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008787267 |\n",
      "|    clip_fraction        | 0.0698      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.146      |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 270         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 391         |\n",
      "|    ep_rew_mean          | 143         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012568893 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.144      |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.000446   |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 389        |\n",
      "|    ep_rew_mean          | 144        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1491       |\n",
      "|    iterations           | 317        |\n",
      "|    time_elapsed         | 435        |\n",
      "|    total_timesteps      | 649216     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03458447 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.154     |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 3160       |\n",
      "|    policy_gradient_loss | 0.00539    |\n",
      "|    std                  | 0.274      |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 389          |\n",
      "|    ep_rew_mean          | 142          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1491         |\n",
      "|    iterations           | 318          |\n",
      "|    time_elapsed         | 436          |\n",
      "|    total_timesteps      | 651264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047695767 |\n",
      "|    clip_fraction        | 0.0839       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.159       |\n",
      "|    explained_variance   | 0.677        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.4         |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.000371    |\n",
      "|    std                  | 0.276        |\n",
      "|    value_loss           | 108          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 393        |\n",
      "|    ep_rew_mean          | 142        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1491       |\n",
      "|    iterations           | 319        |\n",
      "|    time_elapsed         | 438        |\n",
      "|    total_timesteps      | 653312     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01373686 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.173     |\n",
      "|    explained_variance   | 0.816      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24         |\n",
      "|    n_updates            | 3180       |\n",
      "|    policy_gradient_loss | -0.000252  |\n",
      "|    std                  | 0.278      |\n",
      "|    value_loss           | 121        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | 141         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008702656 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.175      |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.74        |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -2.42e-05   |\n",
      "|    std                  | 0.275       |\n",
      "|    value_loss           | 44.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 389          |\n",
      "|    ep_rew_mean          | 146          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1491         |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 440          |\n",
      "|    total_timesteps      | 657408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083691105 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.163       |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 52.3         |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    std                  | 0.275        |\n",
      "|    value_loss           | 165          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 390          |\n",
      "|    ep_rew_mean          | 148          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1491         |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073045916 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.157       |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 25           |\n",
      "|    n_updates            | 3210         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.274        |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 323         |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 661504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015011858 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.156      |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | 0.00317     |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 87.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 397         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 444         |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013240652 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.162      |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 93.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 446         |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009861007 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.157      |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.000855   |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 390       |\n",
      "|    ep_rew_mean          | 168       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 1491      |\n",
      "|    iterations           | 326       |\n",
      "|    time_elapsed         | 447       |\n",
      "|    total_timesteps      | 667648    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0112634 |\n",
      "|    clip_fraction        | 0.121     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    explained_variance   | 0.818     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 92.4      |\n",
      "|    n_updates            | 3250      |\n",
      "|    policy_gradient_loss | -0.000634 |\n",
      "|    std                  | 0.276     |\n",
      "|    value_loss           | 79.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 394         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1491        |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 449         |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007914439 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.163      |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 389         |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1490        |\n",
      "|    iterations           | 328         |\n",
      "|    time_elapsed         | 450         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007182773 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.142      |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.8        |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    std                  | 0.272       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 383          |\n",
      "|    ep_rew_mean          | 158          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1490         |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 452          |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069090324 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.111       |\n",
      "|    explained_variance   | 0.673        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34           |\n",
      "|    n_updates            | 3280         |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    std                  | 0.27         |\n",
      "|    value_loss           | 219          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 383        |\n",
      "|    ep_rew_mean          | 158        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1490       |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 453        |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353464 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.106     |\n",
      "|    explained_variance   | 0.797      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 175        |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | 0.00193    |\n",
      "|    std                  | 0.271      |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 382         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1490        |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 454         |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017837776 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.111      |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | 0.0056      |\n",
      "|    std                  | 0.271       |\n",
      "|    value_loss           | 51.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1490        |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 456         |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007050589 |\n",
      "|    clip_fraction        | 0.0735      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.7        |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | 0.000448    |\n",
      "|    std                  | 0.27        |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | 164          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1490         |\n",
      "|    iterations           | 333          |\n",
      "|    time_elapsed         | 457          |\n",
      "|    total_timesteps      | 681984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149317505 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0981      |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.9         |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | 0.000599     |\n",
      "|    std                  | 0.269        |\n",
      "|    value_loss           | 88.8         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 383         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 459         |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012046062 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0917     |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | 0.000995    |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | 160          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1489         |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 460          |\n",
      "|    total_timesteps      | 686080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074237557 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0836      |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.5         |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | 0.000804     |\n",
      "|    std                  | 0.266        |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 461         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009183319 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0695     |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.6        |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 359         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 337         |\n",
      "|    time_elapsed         | 463         |\n",
      "|    total_timesteps      | 690176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007195215 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0608     |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 464         |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013519628 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0608     |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.6        |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 360         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 465         |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013750083 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0531     |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.000876   |\n",
      "|    std                  | 0.263       |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | 145         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 340         |\n",
      "|    time_elapsed         | 467         |\n",
      "|    total_timesteps      | 696320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012835183 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0333     |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 3390        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012628641 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0134     |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | 0.00113     |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 359         |\n",
      "|    ep_rew_mean          | 142         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 342         |\n",
      "|    time_elapsed         | 470         |\n",
      "|    total_timesteps      | 700416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011456739 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0121      |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.000565   |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | 139         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016467307 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0331      |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.13        |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | 0.0021      |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 59.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | 140         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 472         |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008159571 |\n",
      "|    clip_fraction        | 0.0668      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.036       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.4        |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | 143          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1489         |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 474          |\n",
      "|    total_timesteps      | 706560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097604785 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.043        |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.1         |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.000426    |\n",
      "|    std                  | 0.253        |\n",
      "|    value_loss           | 141          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 359         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 475         |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016040808 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0609      |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | 9.81e-05    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 347         |\n",
      "|    time_elapsed         | 477         |\n",
      "|    total_timesteps      | 710656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009278024 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0693      |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 3460        |\n",
      "|    policy_gradient_loss | 0.000194    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 94.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 478         |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013502771 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0695      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 190         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 148         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010120202 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0849      |\n",
      "|    explained_variance   | 0.62        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.1        |\n",
      "|    n_updates            | 3480        |\n",
      "|    policy_gradient_loss | -0.000788   |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 152         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 481         |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010034806 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0926      |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | 0.000759    |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 69.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 151         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 482         |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009047672 |\n",
      "|    clip_fraction        | 0.0877      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0928      |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | 0.00039     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 95          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 352         |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 720896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016650682 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.107       |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.6        |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | 0.00614     |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 76.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 363         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 485         |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008826399 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.12        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.2        |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 486         |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013042504 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.124       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | 166          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1489         |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 488          |\n",
      "|    total_timesteps      | 727040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058060912 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.126        |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58.3         |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | 0.000394     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 377         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018014152 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.138       |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | 0.00575     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 42.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 378         |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 357         |\n",
      "|    time_elapsed         | 490         |\n",
      "|    total_timesteps      | 731136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014031978 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.143       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.35        |\n",
      "|    n_updates            | 3560        |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 66.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009251717 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.142       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 3570        |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 493         |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009275414 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.138       |\n",
      "|    explained_variance   | 0.716       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 494         |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025788303 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.128       |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 376         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 496         |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025430582 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.11        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | 0.00604     |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 33.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 378         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 362         |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 741376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019230865 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.102       |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 97          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 378         |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 499         |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005987844 |\n",
      "|    clip_fraction        | 0.0694      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0881      |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | 0.000533    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 63          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 384         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 364         |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 745472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764047 |\n",
      "|    clip_fraction        | 0.0858      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0762      |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.000933   |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 210         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 389         |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014464222 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0864      |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 3640        |\n",
      "|    policy_gradient_loss | 0.00521     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 40.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 398         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009589557 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.108       |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | 0.00642     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 400        |\n",
      "|    ep_rew_mean          | 170        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1489       |\n",
      "|    iterations           | 367        |\n",
      "|    time_elapsed         | 504        |\n",
      "|    total_timesteps      | 751616     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01057276 |\n",
      "|    clip_fraction        | 0.087      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.117      |\n",
      "|    explained_variance   | 0.747      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.9       |\n",
      "|    n_updates            | 3660       |\n",
      "|    policy_gradient_loss | 0.00134    |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 58.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 505         |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011813972 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.112       |\n",
      "|    explained_variance   | 0.72        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | 0.00108     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 73.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 507         |\n",
      "|    total_timesteps      | 755712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014192825 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.133       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 3680        |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 403         |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 508         |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012210019 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.165       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 48.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 404         |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 510         |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008529494 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.178       |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 260         |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | 0.000519    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 411         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 372         |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 761856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011852331 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.187       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.38        |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 34.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 411         |\n",
      "|    ep_rew_mean          | 168         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013700485 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.201       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.71        |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | 0.000737    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 45.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 406         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 514         |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015874714 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.204       |\n",
      "|    explained_variance   | 0.744       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 67.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008749593 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.208       |\n",
      "|    explained_variance   | 0.64        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 411         |\n",
      "|    ep_rew_mean          | 174         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 376         |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013643129 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.233       |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | 0.0028      |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 47.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 411         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 518         |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013533445 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.259       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38        |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 45.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 411         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 519         |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504532 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.275       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 39.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 414         |\n",
      "|    ep_rew_mean          | 187         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 379         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 776192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014679795 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.281       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 3780        |\n",
      "|    policy_gradient_loss | -0.000685   |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 42.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 402         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010923937 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.273       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.54        |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | 0.00493     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 25.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 381         |\n",
      "|    time_elapsed         | 523         |\n",
      "|    total_timesteps      | 780288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091802 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.262       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 406         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 409         |\n",
      "|    ep_rew_mean          | 176         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 525         |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016274933 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.249       |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 413         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 526         |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012012714 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.247       |\n",
      "|    explained_variance   | 0.613       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.000949   |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 64.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 408         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209493 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.252       |\n",
      "|    explained_variance   | 0.702       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | 7.08e-05    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 84.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 391         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 529         |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007919963 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.261       |\n",
      "|    explained_variance   | 0.525       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 320         |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | 180         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 386         |\n",
      "|    time_elapsed         | 530         |\n",
      "|    total_timesteps      | 790528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009923106 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.266       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.1        |\n",
      "|    n_updates            | 3850        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 390         |\n",
      "|    ep_rew_mean          | 182         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013560193 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.266       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.8        |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | 0.00218     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006210764 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.275       |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | 0.00241     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 391         |\n",
      "|    ep_rew_mean          | 188         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018247228 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.276       |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | 0.00419     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 79.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 377         |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 536         |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012759829 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.278       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.000609   |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 53.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 376        |\n",
      "|    ep_rew_mean          | 192        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1489       |\n",
      "|    iterations           | 391        |\n",
      "|    time_elapsed         | 537        |\n",
      "|    total_timesteps      | 800768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614763 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.28       |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.7       |\n",
      "|    n_updates            | 3900       |\n",
      "|    policy_gradient_loss | -0.00142   |\n",
      "|    std                  | 0.225      |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 538         |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014132328 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.29        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021717403 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.297       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | 0.00473     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 29.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 365         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 541         |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008916119 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.293       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 542         |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009497162 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.293       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | 0.000517    |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 396         |\n",
      "|    time_elapsed         | 544         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012985569 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.294       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.4        |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.000288   |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852261 |\n",
      "|    clip_fraction        | 0.0823      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.3         |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.6        |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 371         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 547         |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008378851 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.305       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.9        |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 363         |\n",
      "|    ep_rew_mean          | 179         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008187515 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.308       |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 60.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 549         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012344282 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.3         |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 401         |\n",
      "|    time_elapsed         | 551         |\n",
      "|    total_timesteps      | 821248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009804914 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.287       |\n",
      "|    explained_variance   | 0.695       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 359         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 552         |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023626324 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.282       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 360        |\n",
      "|    ep_rew_mean          | 182        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1489       |\n",
      "|    iterations           | 403        |\n",
      "|    time_elapsed         | 553        |\n",
      "|    total_timesteps      | 825344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01232216 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.293      |\n",
      "|    explained_variance   | 0.643      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.8       |\n",
      "|    n_updates            | 4020       |\n",
      "|    policy_gradient_loss | 0.00214    |\n",
      "|    std                  | 0.225      |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 358         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 555         |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331217 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.296       |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.6        |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | 0.000746    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 60.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 345          |\n",
      "|    ep_rew_mean          | 174          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1489         |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 556          |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074714134 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.291        |\n",
      "|    explained_variance   | 0.555        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.7         |\n",
      "|    n_updates            | 4040         |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 119          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 406         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 831488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008184241 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.295       |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 4050        |\n",
      "|    policy_gradient_loss | 0.000863    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 166         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 559         |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009352844 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.302       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.9        |\n",
      "|    n_updates            | 4060        |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 408         |\n",
      "|    time_elapsed         | 560         |\n",
      "|    total_timesteps      | 835584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013450606 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.308       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 4070        |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 164         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009058457 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.316       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 4080        |\n",
      "|    policy_gradient_loss | 0.00282     |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 563         |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011944595 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.337       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81          |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 411         |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 841728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010679872 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.347       |\n",
      "|    explained_variance   | 0.733       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.59        |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | 0.00512     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 34.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | 173         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008780772 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.35        |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 361         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010883488 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.365       |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | 0.00353     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 62.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 569         |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009584922 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.372       |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | 178         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 570         |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014248098 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.374       |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.86        |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | 0.005       |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 53.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | 180         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 416         |\n",
      "|    time_elapsed         | 571         |\n",
      "|    total_timesteps      | 851968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009175551 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.378       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 4150        |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 85.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013396939 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.384       |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | 1.28e-05    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 336         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1489        |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 574         |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287576 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.393       |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 339          |\n",
      "|    ep_rew_mean          | 169          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1488         |\n",
      "|    iterations           | 419          |\n",
      "|    time_elapsed         | 576          |\n",
      "|    total_timesteps      | 858112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0124058835 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.391        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 320          |\n",
      "|    n_updates            | 4180         |\n",
      "|    policy_gradient_loss | 0.00012      |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 289          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 420         |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011724146 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.389       |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | 0.000305    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 341        |\n",
      "|    ep_rew_mean          | 164        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1488       |\n",
      "|    iterations           | 421        |\n",
      "|    time_elapsed         | 579        |\n",
      "|    total_timesteps      | 862208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00951372 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.394      |\n",
      "|    explained_variance   | 0.294      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 87.8       |\n",
      "|    n_updates            | 4200       |\n",
      "|    policy_gradient_loss | 0.000843   |\n",
      "|    std                  | 0.218      |\n",
      "|    value_loss           | 306        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 163         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 580         |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011052355 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.394       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 4210        |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 360         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 423         |\n",
      "|    time_elapsed         | 581         |\n",
      "|    total_timesteps      | 866304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018194491 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.369       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.3        |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | 0.00156     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 64.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 583         |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026006162 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.358       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.5        |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 55.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 365         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 425         |\n",
      "|    time_elapsed         | 584         |\n",
      "|    total_timesteps      | 870400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012059592 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.367       |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | 0.00087     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 363        |\n",
      "|    ep_rew_mean          | 162        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1488       |\n",
      "|    iterations           | 426        |\n",
      "|    time_elapsed         | 586        |\n",
      "|    total_timesteps      | 872448     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01141719 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.368      |\n",
      "|    explained_variance   | 0.63       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.4       |\n",
      "|    n_updates            | 4250       |\n",
      "|    policy_gradient_loss | 0.00436    |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 106        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 587         |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008757309 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.356       |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.3        |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 95.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016115848 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.367       |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.8        |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 51.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | 159         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008502232 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.372       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.6        |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | 0.00235     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 430         |\n",
      "|    time_elapsed         | 591         |\n",
      "|    total_timesteps      | 880640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012467612 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.369       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.2        |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | 0.00081     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | 153         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 593         |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011248625 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.373       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 368         |\n",
      "|    ep_rew_mean          | 149         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 594         |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011320604 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.384       |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | 0.00236     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 95.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | 147         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 595         |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009341339 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.401       |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.8        |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | 0.00125     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | 144         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 597         |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009736231 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.405       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 382         |\n",
      "|    ep_rew_mean          | 146         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 435         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 890880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053536672 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.396       |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4         |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | 0.00601     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 57.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | 150         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011376509 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.394       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 380         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 601         |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011514321 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.406       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 388         |\n",
      "|    ep_rew_mean          | 157         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 602         |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015756734 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.412       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 94.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 386         |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 604         |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017766934 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.403       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -4.3e-05    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 394         |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 440         |\n",
      "|    time_elapsed         | 605         |\n",
      "|    total_timesteps      | 901120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098026 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.402       |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24          |\n",
      "|    n_updates            | 4390        |\n",
      "|    policy_gradient_loss | 1.84e-05    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 67.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 376          |\n",
      "|    ep_rew_mean          | 175          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1488         |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 606          |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0111681735 |\n",
      "|    clip_fraction        | 0.121        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.399        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 61.6         |\n",
      "|    n_updates            | 4400         |\n",
      "|    policy_gradient_loss | 0.00151      |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 442         |\n",
      "|    time_elapsed         | 608         |\n",
      "|    total_timesteps      | 905216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010756217 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.403       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.4        |\n",
      "|    n_updates            | 4410        |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009364143 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.411       |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | 174         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 611         |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013656167 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.413       |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 445         |\n",
      "|    time_elapsed         | 612         |\n",
      "|    total_timesteps      | 911360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012547366 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.424       |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | 0.00423     |\n",
      "|    std                  | 0.214       |\n",
      "|    value_loss           | 62.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 358         |\n",
      "|    ep_rew_mean          | 165         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 613         |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014236096 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.437       |\n",
      "|    explained_variance   | 0.612       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 4450        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | 173         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 615         |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014009105 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.432       |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.68        |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 72.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 359         |\n",
      "|    ep_rew_mean          | 172         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007639106 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.428       |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 92.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 617         |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009992272 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.428       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.6        |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 450         |\n",
      "|    time_elapsed         | 619         |\n",
      "|    total_timesteps      | 921600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011784958 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.429       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 620         |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010668503 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.432       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.9        |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 350        |\n",
      "|    ep_rew_mean          | 167        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1488       |\n",
      "|    iterations           | 452        |\n",
      "|    time_elapsed         | 622        |\n",
      "|    total_timesteps      | 925696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817763 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.442      |\n",
      "|    explained_variance   | 0.523      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.1       |\n",
      "|    n_updates            | 4510       |\n",
      "|    policy_gradient_loss | 0.00063    |\n",
      "|    std                  | 0.213      |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 162         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015670434 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.453       |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.86        |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | 0.00451     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 86.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 161         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011063919 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.465       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 337        |\n",
      "|    ep_rew_mean          | 157        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1488       |\n",
      "|    iterations           | 455        |\n",
      "|    time_elapsed         | 626        |\n",
      "|    total_timesteps      | 931840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01761295 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.481      |\n",
      "|    explained_variance   | 0.619      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55.4       |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.00097   |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | 158         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 627         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011656776 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.478       |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.4        |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | 154         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 628         |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031180387 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.481       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08        |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | 0.016       |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 20.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 155         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 630         |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008303789 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.497       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.5        |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 160         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1488        |\n",
      "|    iterations           | 459         |\n",
      "|    time_elapsed         | 631         |\n",
      "|    total_timesteps      | 940032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010612166 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.499       |\n",
      "|    explained_variance   | 0.539       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | 0.0028      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 46.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024035115 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.514       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.42        |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | 0.00616     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 36.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 349         |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 634         |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023477558 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.54        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 98.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | 169         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008318869 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.551       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.000936   |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 350         |\n",
      "|    ep_rew_mean          | 170         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 637         |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011703817 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.561       |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 356          |\n",
      "|    ep_rew_mean          | 173          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1487         |\n",
      "|    iterations           | 464          |\n",
      "|    time_elapsed         | 638          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153564755 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.569        |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 46.7         |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.203        |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | 177         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014318263 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.581       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | 0.000112    |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | 181         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 641         |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014513596 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.58        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 340         |\n",
      "|    ep_rew_mean          | 187         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 642         |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013818485 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.579       |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | 190         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 644         |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014982572 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.582       |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | 0.00294     |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 342         |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 469         |\n",
      "|    time_elapsed         | 645         |\n",
      "|    total_timesteps      | 960512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011220777 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.586       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 337        |\n",
      "|    ep_rew_mean          | 197        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 1487       |\n",
      "|    iterations           | 470        |\n",
      "|    time_elapsed         | 647        |\n",
      "|    total_timesteps      | 962560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02221824 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.59       |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 4690       |\n",
      "|    policy_gradient_loss | 0.000901   |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 124        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 341         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012967868 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.595       |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.000775   |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 89.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 325          |\n",
      "|    ep_rew_mean          | 204          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1487         |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 649          |\n",
      "|    total_timesteps      | 966656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150179155 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.596        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.2         |\n",
      "|    n_updates            | 4710         |\n",
      "|    policy_gradient_loss | 0.00391      |\n",
      "|    std                  | 0.202        |\n",
      "|    value_loss           | 80.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 325         |\n",
      "|    ep_rew_mean          | 205         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 651         |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020532256 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.604       |\n",
      "|    explained_variance   | 0.686       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.000934   |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 317         |\n",
      "|    ep_rew_mean          | 202         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 474         |\n",
      "|    time_elapsed         | 652         |\n",
      "|    total_timesteps      | 970752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010606837 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.601       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | 0.00275     |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 181         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | 203         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021900173 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.599       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | 0.000194    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 311         |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 655         |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012609983 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.626       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | 0.00762     |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 62.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 199         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 477         |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 976896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010408417 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.65        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 240         |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 338         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 201         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 658         |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012481388 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.652       |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.000143   |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 304         |\n",
      "|    ep_rew_mean          | 198         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 479         |\n",
      "|    time_elapsed         | 659         |\n",
      "|    total_timesteps      | 980992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011252481 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.646       |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.000214   |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 200         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 660         |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014875055 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.634       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 662         |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012587747 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.624       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.3        |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 303         |\n",
      "|    ep_rew_mean          | 192         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 663         |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008277568 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.611       |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 300         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 664         |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014213419 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.613       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 97.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | 196         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 484         |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 991232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010062225 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.625       |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 72.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 294         |\n",
      "|    ep_rew_mean          | 193         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010063365 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.634       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | 0.000474    |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 292         |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 486         |\n",
      "|    time_elapsed         | 669         |\n",
      "|    total_timesteps      | 995328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013662592 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.639       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.4        |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 295         |\n",
      "|    ep_rew_mean          | 195         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 670         |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015070372 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.653       |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | 0.000508    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 293         |\n",
      "|    ep_rew_mean          | 189         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 672         |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016002124 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.647       |\n",
      "|    explained_variance   | 0.717       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 75.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 286         |\n",
      "|    ep_rew_mean          | 183         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1487        |\n",
      "|    iterations           | 489         |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 1001472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011776368 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.642       |\n",
      "|    explained_variance   | 0.529       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.1        |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x2bc417fa150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create PPO model using your existing env\n",
    "ppo_model = PPO(\"MlpPolicy\", env, verbose=0, tensorboard_log=\"./ppo_lunar_tensorboard/\")\n",
    "\n",
    "# Train PPO\n",
    "total_timesteps = 1_000_000\n",
    "eval_interval = 5000\n",
    "eval_episodes = 10\n",
    "\n",
    "episode_rewards = []\n",
    "eval_results = []\n",
    "timesteps = 0\n",
    "\n",
    "def evaluate(model, env, n_episodes=10):\n",
    "    rewards = []\n",
    "    for _ in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            total_reward += reward\n",
    "        rewards.append(total_reward)\n",
    "    return np.mean(rewards), rewards\n",
    "\n",
    "while timesteps < total_timesteps:\n",
    "    ppo_model.learn(total_timesteps=eval_interval, reset_num_timesteps=False)\n",
    "    timesteps += eval_interval\n",
    "\n",
    "    eval_env = gym.make(\n",
    "        \"LunarLander-v3\",\n",
    "        gravity=-10,\n",
    "        continuous=True,\n",
    "        enable_wind=True,\n",
    "        wind_power=15.0,\n",
    "        turbulence_power=1.5,\n",
    "    )\n",
    "    eval_env.reset(seed=seed_value)\n",
    "\n",
    "    mean_reward, rewards = evaluate(ppo_model, eval_env, n_episodes=eval_episodes)\n",
    "    episode_rewards.append(mean_reward)\n",
    "    eval_results.append({\"timesteps\": timesteps, \"mean_reward\": mean_reward})\n",
    "\n",
    "    print(f\"Evaluation at step {timesteps}: Mean Reward = {mean_reward:.2f}\")\n",
    "\n",
    "    eval_env.close()\n",
    "\n",
    "ppo_model.save(\"ppo_lunar_vanilla\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f82a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707dd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = gym.make(\n",
    "    \"LunarLander-v3\",\n",
    "    gravity=-10,\n",
    "    continuous=True,\n",
    "    enable_wind=True, \n",
    "    wind_power=15.0,\n",
    "    turbulence_power=1.5,\n",
    "    render_mode=None  \n",
    ")\n",
    "test_env.reset(seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ed58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df[\"timesteps\"], results_df[\"mean_reward\"], linewidth=2)\n",
    "plt.axhline(y=200, color='red', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Mean Evaluation Return\")\n",
    "plt.title(\"PPO (Default) Evaluation Performance Over Time\")\n",
    "plt.grid(True)\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816b67b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_reward = results_df[\"mean_reward\"].min()\n",
    "max_reward = results_df[\"mean_reward\"].max()\n",
    "bins = np.arange(\n",
    "    start=np.floor(min_reward / 25) * 25,\n",
    "    stop=np.ceil(max_reward / 25) * 25 + 25,\n",
    "    step=25\n",
    ")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(results_df[\"mean_reward\"], bins=bins, edgecolor='k')\n",
    "plt.xlabel(\"Mean Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"PPO (Default): Distribution of Mean Evaluation Rewards\")\n",
    "plt.grid(True, axis='x')\n",
    "plt.grid(True, axis='y', which='both')\n",
    "plt.xticks(bins, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666f42d",
   "metadata": {},
   "source": [
    "The second experiment explores the impact of custom hyperparameters. In this setup:\n",
    "- The neural network is deeper (two layers of 256 units for both policy and value)\n",
    "- Batch size and rollout length are increased\n",
    "- Learning rate and entropy coefficient are decreased\n",
    "- More epochs are used per update\n",
    "\n",
    "The goal is to determine whether these adjustments lead to faster learning or higher average rewards compared to the default setup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\n",
    "    \"LunarLander-v3\",\n",
    "    gravity=-10,\n",
    "    continuous=True,\n",
    "    enable_wind=True,\n",
    "    wind_power=15.0,\n",
    "    turbulence_power=1.5\n",
    ")\n",
    "env.reset(seed=seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print('State dimension:', state_dim)\n",
    "print('Action dimension:', action_dim)\n",
    "print('Action range:', action_low, 'to', action_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ebba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model_custom = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    n_steps=4096,           # Larger rollout for better GAE estimation\n",
    "    batch_size=256,         # Larger minibatch\n",
    "    gae_lambda=0.97,        # Slightly lower for less bias, more variance\n",
    "    gamma=0.99,             # Discount factor\n",
    "    ent_coef=0.005,         # Less entropy bonus\n",
    "    learning_rate=1e-4,     # Lower LR for more stable convergence\n",
    "    n_epochs=20,            # More epochs\n",
    "    clip_range=0.2,         # Default\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_lunar_tensorboard/\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71024e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 1_000_000\n",
    "eval_interval = 5000\n",
    "eval_episodes = 10\n",
    "\n",
    "episode_rewards_custom = []\n",
    "eval_results_custom = []\n",
    "timesteps = 0\n",
    "\n",
    "while timesteps < total_timesteps:\n",
    "    ppo_model_custom.learn(total_timesteps=eval_interval, reset_num_timesteps=False)\n",
    "    timesteps += eval_interval\n",
    "\n",
    "    eval_env = gym.make(\n",
    "        \"LunarLander-v3\",\n",
    "        gravity=-10,\n",
    "        continuous=True,\n",
    "        enable_wind=True,\n",
    "        wind_power=15.0,\n",
    "        turbulence_power=1.5,\n",
    "    )\n",
    "    eval_env.reset(seed=seed_value)\n",
    "\n",
    "    mean_reward, rewards = evaluate(ppo_model_custom, eval_env, n_episodes=eval_episodes)\n",
    "    episode_rewards_custom.append(mean_reward)\n",
    "    eval_results_custom.append({\"timesteps\": timesteps, \"mean_reward\": mean_reward})\n",
    "\n",
    "    print(f\"Custom PPO - Evaluation at step {timesteps}: Mean Reward = {mean_reward:.2f}\")\n",
    "\n",
    "    eval_env.close()\n",
    "\n",
    "ppo_model_custom.save(\"ppo_lunar_custom\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f41f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_custom = pd.DataFrame(eval_results_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5379912",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = gym.make(\n",
    "    \"LunarLander-v3\",\n",
    "    gravity=-10,\n",
    "    continuous=True,\n",
    "    enable_wind=True,\n",
    "    wind_power=15.0,\n",
    "    turbulence_power=1.5,\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "test_env.reset(seed=seed_value)\n",
    "\n",
    "# Load the model (already saved previously, or use the variable from training)\n",
    "ppo_model = PPO.load(\"ppo_lunar_vanilla\")\n",
    "\n",
    "# Run and render a few episodes\n",
    "for ep in range(10):\n",
    "    obs, _ = test_env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "        obs, reward, terminated, truncated, _ = test_env.step(action)\n",
    "        done = terminated or truncated\n",
    "        total_reward += reward\n",
    "    print(f\"Test Episode {ep+1}: Reward = {total_reward:.2f}\")\n",
    "test_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd632786",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(results_df_custom[\"timesteps\"], results_df_custom[\"mean_reward\"], linewidth=2)\n",
    "plt.axhline(y=200, color='red', linestyle='--', linewidth=1.5)\n",
    "plt.xlabel(\"Timesteps\")\n",
    "plt.ylabel(\"Mean Evaluation Return\")\n",
    "plt.title(\"PPO (Custom) Evaluation Performance Over Time\")\n",
    "plt.grid(True)\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_reward_custom = results_df_custom[\"mean_reward\"].min()\n",
    "max_reward_custom = results_df_custom[\"mean_reward\"].max()\n",
    "bins_custom = np.arange(\n",
    "    start=np.floor(min_reward_custom / 25) * 25,\n",
    "    stop=np.ceil(max_reward_custom / 25) * 25 + 25,\n",
    "    step=25\n",
    ")\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(results_df_custom[\"mean_reward\"], bins=bins_custom, edgecolor='k')\n",
    "plt.xlabel(\"Mean Reward\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"PPO (Custom): Distribution of Mean Evaluation Rewards\")\n",
    "plt.grid(True, axis='x')\n",
    "plt.grid(True, axis='y', which='both')\n",
    "plt.xticks(bins_custom, rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
